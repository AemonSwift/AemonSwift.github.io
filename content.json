{"meta":{"title":"长亭短亭","subtitle":"Man Propose, God Dispose.","description":null,"author":"AemonSwift","url":"http://aemonswift.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-10-24T02:01:31.000Z","updated":"2019-10-24T02:08:24.653Z","comments":true,"path":"categories/index.html","permalink":"http://aemonswift.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-10-24T02:01:12.000Z","updated":"2019-10-24T02:08:13.934Z","comments":true,"path":"tags/index.html","permalink":"http://aemonswift.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"mysql优化之使用规范","slug":"mysql优化之使用规范","date":"2019-11-03T13:05:23.000Z","updated":"2019-11-04T07:49:55.571Z","comments":true,"path":"2019/11/03/mysql优化之使用规范/","link":"","permalink":"http://aemonswift.github.io/2019/11/03/mysql%E4%BC%98%E5%8C%96%E4%B9%8B%E4%BD%BF%E7%94%A8%E8%A7%84%E8%8C%83/","excerpt":"","text":"基础规范1. 使用InnoDB存储引擎支持事务、行级锁、并发性能更好、CPU及内存缓存页优化使得资源利用率更高 2. 推荐使用utf8mb4字符集无需转码，无乱码风险, 支持emoji表情以及部分不常见汉字 3. 表、字段必须加注释 方便他人理解字段意思，在后期维护中非常非常有用，不用去瞎猜这个字段是干嘛的。 4. 不在数据库做计算禁止使用存储过程、视图、触发器、Event。在并发量大的情况下，这些功能很可能将数据库拖跨，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。 5. 禁止存储文件文件存储在文件系统，数据库里存URI 6. 控制单表数据量单表记录控制在千万级，超过了可以进行分库分表 7. 不要在数据库中进行排序。特别是大数据量的排序，可考虑在程序中设计排序； 8. 不要对数据做真正意义的物理删除(DELETE…)。可考虑逻辑删除，即在表中设计一个is_deleted字段标记该字段是否删除，防止毁灭性事件的发生； 9. 避免在数据库中做计算，减轻数据库压力10. 避免JOIN查询，请尽可能的使用单表查询，减少查询复杂度，减轻数据库压力11. 禁止在数据库中使用视图、存储过程、函数、触发器、事件命名规范1. 库名、表名、字段名、索引名：小写，下划线风格非唯一索引按照”ix字段名称[字段名称]”进行命名，如ix_uid_name;唯一索引按照”uk字段名称[字段名称]”进行命名，如uk_uid_name; 2. 表必须有主键，例如自增主键a. 主键递增，数据行写入可以提高插入性能;b. 主键要选择较短的数据类型，Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率;c. 保证实体的完整性，唯一性。 3. 不要使用外键。如果有外键约束，用应用程序控制。外键会导致表与表之间耦合，update与delete操作都会涉及相关联的表，十分影响sql 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能下降，大数据高并发业务场景数据库使用以性能优先。 字段设计规范1. 把字段定义为NOT NULL并且提供默认值。 数值类型使用：NOT NULL DEFAULT 0 字符类型使用：NOT NULL DEFAULT “” $\\color{red}{timestamp类型不指定默认值的话，MariaDB 会默认给0；多于一个timestamp字段没有指定默认值，会自动给一个timestamp默认值为 CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP，其他为0。}$ 主要原因在于： a. null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化;b. null 这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多;c. null值需要更多的存储空间，无论是表还是索引中每行中的null的列都需要额外的空间来标识;d. 对null 的处理时候，只能采用is null或is not null，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’zhangsan’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录。 2. 不要使用TEXT、BLOB类型会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能,如果必须要使用则独立出来一张表，用主键来对应，避免影响其它字段索引效率。 3. 避免使用浮点数类型计算机处理整型比浮点型快N倍，如果必须使用，请将浮点型扩大N倍后转为整型；建议使用整数，小数容易导致钱对不上。即通常做法为：涉及精确金额相关用途的字段类型，强烈建议扩大N倍后转换成整型存储（例如金额中的分扩大百倍后存储成整型），避免浮点数加减出现不准确的问题，也强烈建议比实际需求多保留一位，便于后续财务方面对账更加准确 4. 必须使用varchar存储手机号手机号会去做数学运算么？ 5. 为提高效率可以牺牲范式设计，冗余数据冗余字段选择要求：a. 不是频繁修改的字段;b. 不是 varchar 超长字段，更不能是 text 字段。 6. 所有表都必须要有主键主键类型必须为：INT/BIGINT unsigned NOT NULL AUTO_INCREMENT，提高顺序insert效率，强烈建议该列与业务没有联系，并且不建议使用组合主键，仅仅作为自增主键id使用。INT／BIGINT如何选择？a. 当表的预估数据量在42亿条以内，请使用INT UNSIGNED；b. 当表的预估数据量超过42亿条，请使用BIGINT UNSIGNED;为什么选择自增id作为主键？a. 主键自增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用b. 自增型主键设计(int,bigint)可以降低二级索引的空间，提升二级索引的内存命中率；c. 主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率;d. 无主键的表删除，在row模式的主从架构，会导致备库夯住。 7. 所有表必须携带ctime(创建时间),mtime(最后修改时间)这两个字段，便于数据分析以及故障排查；123#两个字段的类型如下，只需要在建表时建立即可，不需要开发人员再往其中插入时间值，前提是INSERT INTO语句显示的字段名称：ctime TIMESATMP NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT ‘创建时间’;mtime TIMESATMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT ‘最后修改时间’ 9. 对于CHAR(N)/VARCHAR(N)类型，在满足够用的前提下，尽可能小的选择N的大小，并且建议N&lt;255，用于节省磁盘空间和内存空间；10. 使用TINYINT代替ENUM类型，新增ENUM类型需要在DDL操作，对于TINYINT类型在数据库字段COMMENT和程序代码中做好备注信息，避免混淆12num enum('0','1','2','3') comment 'enum枚举类型' );`num` tinyint(4) NOT NULL DEFAULT '0' COMMENT 'TINY枚举类型：0-不通过，1-通过' 10. JOIN查询时，用于JOIN的字段定义必须完全相同(避免隐式转换)，并且建立索引。11. 存储单个IP时，必须使用整型INT UNSIGNED类型，不允许使用字符型VARCHAR()存储单个IP。时间类型，首选使用整型INT、INT UNSIGNED类型，其次使用timestamp类型。 INT: 存储范围：-2147483648 to 2147483647 对应的时间范围: 1970/1/1 8:00:00 – 2038/1/19 11:14:07 INT UNSIGNED: 存储范围：0 to 4294967295 对应的时间范围：1970/1/1 8:00:00 – 2106/2/7 14:28:1512. 日期类型，请使用date类型。 索引设计规范1. 禁止在更新十分频繁、区分度不高的属性上建立索引a. 更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能;b. “性别”这种区分度不大的属性，建立索引是没有什么意义的，故找区分度大的字段作为索引。 2. 建立组合索引，必须把区分度高的字段放在最左边因为使用单字段查询时会使用组合索引的左边字段而不使用右边的字段，如果 where a=? and b=? ， a 列的几乎接近于唯一值，那么只需要单建 idx_a 索引即可。 3. 页面搜索严禁左模糊或者全模糊索引文件具有 B-Tree 的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引, 如果需要请走搜索引擎来解决。 SQL使用规范1. 禁止使用SELECT *，只获取必要的字段，需要显示说明列属性a. 消耗cpu，io，内存，带宽;b. 不能有效的利用覆盖索引;c. 使用SELECT *容易在增加或者删除字段后出现程序BUG, 不具有扩展性。d. 没有避免新增字段对程序应用逻辑的影响 2. 使用INSERT INTO t_xxx VALUES(xxx)，必须显示指定插入的列属性容易在增加或者删除字段后出现程序BUG 3. 务必请使用“同类型”进行比较，否则可能全表扫面SELECT name FROM t_user WHERE phone=1888888888 会导致全表扫描. 4. 禁止在WHERE条件的上使用函数或者计算解读：SELECT naem FROM tuser WHERE date(createdatatime)=’2017-12-29’ 会导致全表扫描推荐的写法是：SELECT name FROM tuser WHERE createdatatime&gt;= ‘2017-12-29’ and create_datatime &lt; ‘2017-12-30’ 5. 禁止负向查询，以及%开头的模糊查询a. 负向查询条件：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等，会导致全表扫描。b. %开头的模糊查询，会导致全表扫描。 6. 不要大表使用JOIN查询，禁止大表使用子查询会产生临时表，消耗较多内存与CPU，极大影响数据库性能。 7. OR改写为IN()或者UNION原因很简单or不会走索引。 8. 简单的事务事务就像程序中的锁一样粒度尽可能要小。 9. 不要一次更新大量数据数据更新会对行或者表加锁，应该分为多次更新。 10. 生产环境中，表一旦设计好，字段只允许增加(ADD COLUMN)，禁止减少(DROP COLUMN)，禁止改名称(CHANGE/MODIFY COLUMN);11. 禁止使用UPDATE … LIMIT …和DELETE … LIMIT …操作因为你无法得知自己究竟更新或者删除了哪些数据，请务必添加ORDER BY进行排序 12345678# 这是错误的语法示例UPDATE tb SET col1=value1 LIMIT n;# 这是错误的语法示例DELETE FROM tb LIMIT n;# 这是正确的语法示例UPDATE tb SET col1=value1 ORDER BY id LIMIT n;# 这是正确的语法示例DELETE FROM tb ORDER BY id LIMIT n; 12. 禁止超过2张表的JOIN查询13. 禁止使用子查询14. 禁止出现冗余索引，如索引(a),索引(a,b)，此时索引(a)为冗余索引;15. 禁止使用ORDER BY RAND()排序，性能极其低下。16. 禁止使用外键，外键的逻辑应当由程序去控制外键会导致表与表之间耦合，UPDATE与DELETE操作都会涉及相关联的表，十分影响SQL 的性能，甚至会造成死锁。高并发情况下容易造成数据库性能，大数据高并发业务场景数据库使用以性能优先。 17. 禁止回退表的DDL操作例子1. 创建表12345678910111213# 这是正确的语法示范CREATE TABLE `test` ( `c1` int(11) NOT NULL AUTO_INCREMENT COMMENT '自增主键ID', `c2` int(11) NOT NULL DEFAULT '0' COMMENT '无符号数值型字段', `c3` int(11) NOT NULL DEFAULT '0' COMMENT '有符号数值型字段', `c4` varchar(16) NOT NULL DEFAULT '0' COMMENT '变长字符型字段', `ctime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间类型字段', `mtime` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间类型字段', `c7` tinyint(4) NOT NULL DEFAULT '0' COMMENT '枚举类型字段：0-xxx,1-xxx,2-xxx', PRIMARY KEY (`c1`), UNIQUE KEY `uk_c2` (`c2`), KEY `ix_c3` (`c3`)) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='测试表' 更改表添加字段12# 这是正确的语法示范ALTER TABLE test ADD COLUMN c8 int(11) NOT NULL DEFAULT 0 COMMENT '添加字段测试'; 添加字段时禁止使用after/before属性，避免数据偏移。 变更字段12345# 这是正确的语法示范# MODIFY只修改字段定义（优先使用）ALTER TABLE test MODIFY COLUMN c8 varchar(16) NOT NULL DEFAULT 0 COMMENT 'MODIFY修改字段定义';# CHANGE修改字段名称ALTER TABLE test CHANGE COLUMN c7 c8 varchar(16) NOT NULL DEFAULT 0 COMMENT 'CHANGE修改字段名称'; 删除字段12# 这是正确的语法示范ALTER TABLE test DROP COLUMN c8; 添加主键12# 这是正确的语法示范ALTER TABLE test ADD PRIMARY KEY(c1); 删除主键12# 这是正确的语法示范ALTER TABLE test DROP PRIMARY KEY; 添加普通索引12# 这是正确的语法示范alter table test add INDEX ix_c3(c3); 如果创建的是联合索引，筛选度高的列靠左 添加唯一索引12# 这是正确的语法示范alter table test add UNIQUE INDEX uk_c2(c2); 删除普通索引12# 这是正确的语法示范alter table test DROP INDEX ix_c3; 删除唯一索引12# 这是正确的语法示范alter table test DROP INDEX uk_c2; 同一张表的修改语句请合并，避免多次重建表影响读写 1alter table test add col1 int(11) NOT NULL DEFAULT 0 COMMENT 'col1字段用途',add index idx_col2(col2),modify col3 varchar(16) NOT NULL DEFAULT '' COMMENT 'col3字段用途' 插入语句12# INSERT INTO语句的正确语法示例INSERT INTO tb(col1,col2) VALUES(value1,values2); INSERT INTO语句需要显示指明字段名称;对于多次单条INSERT INTO语句，务必使用批量INSERT INTO语句，提高INSERT INTO语句效率，如： 123456# 多次单条INSERT INTO，这是错误的语法示例INSERT INTO test(col1,col2) VALUES(value1,values2);INSERT INTO test(col1,col2) VALUES(value3,values4);INSERT INTO test(col1,col2) VALUES(value5,values6);# 批量INSERT INTO语句，这是正确的语法示例INSERT INTO test(col1,col2) VALUES(value1,values2),(value3,values4),(value5,values6); 更新语句12# UPDATE语句的正确语法示例UPDATE tb SET col1=value1,col2=value2,col3=value3 WHERE col0=value0 AND col5=value5; SET后接的并列字段分隔符为”逗号(,)”，而不是常见的”AND”，使用”AND”也能将UPDATE语句执行成功，但意义完全不一样。原来在UPDATE … SET后接分隔符为”AND”的语句，由于AND的优先级较高，所以先处理“AND”，再处理“＝”，于是“＝”后面的值只有逻辑运算的结果true(1) / false(0)。例如：update t set c1=11 and c2=’AA’ where id=1; 在这条语句中MySQL将c1=11 and c2=’AA’解析成了c1=(11 and c2=’AA’)强烈建议UPDATE语句后携带WHERE条件，防止灾难性事件的发生；使用UPDATE修改大量数据时，该语句极易引起主从复制延迟；禁止使用UPDATE … LIMIT …语法 查询语句1234# 这是错误的语法示范SELECT * FROM tb WHERE col1=value1;# 这是正确的语法示范SELECT col1,col2 FROM tb WHERE col1=value1; 禁止使用SELECT * FROM语句，SELECT只获取需要的字段，既防止了新增字段对程序应用逻辑的影响，又减少了对程序和数据库的性能影响；合理的使用数据类型，避免出现隐式转换，隐式转换无法使用索引且效率低，如：SELECT name FROM tb WHERE id=’1’;,此时id为int类型，此时出现隐式转换［这是错误的语法示范］；不建议使用％前缀模糊查询，导致查询无法使用索引，如：SELECT id FROM tb WHERE name LIKE ‘%test’;［这是错误的语法示范］；对于LIMIT操作，强烈建议使先ORDER BY 再LIMIT，即ORDER BY c1 LIMIT n； 删除语句12# DELETE语句的正确语法示例DELETE FROM tb WHERE col0=value0 AND col1=value1; 强烈建议DELETE语句后携带WHERE条件，防止灾难性事件的发生；使用DELETE修改大量数据时，该语句极易引起主从复制延迟；禁止使用DELETE … LIMIT …语法 其它书写规范 禁止再where后面给字段使用mysql中的函数1234# 这是错误的语法示范SELECT col1,col2 FROM test WHERE unix_timestamp(col1)=value1;# 这是正确的语法示范SELECT col1,col2 FROM test WHERE col1=unix_timestamp(value1); 强烈建议字段放在操作符左边1234# 这是错误的语法示范SELECT col1,col2 FROM tb WHERE value1=col1l# 这是正确的语法示范SELECT col1,col2 FROM tb WHERE col1=value1; 禁止将字符类型传入到整型类型字段中，也禁止整形类型传入到字段类型中，存在隐式转换的问题；12345678910# 这是错误的语法示范# var_col字段为VARCHAR类型SELECT col1,col2 FROM test WHERE var_col=123;# int_col字段为INT类型SELECT col1,col2 FROM test WHERE int_col='123';# 这是正确的语法示范# var_col字段为VARCHAR类型SELECT col1,col2 FROM test WHERE var_col='123';# int_col字段为INT类型SELECT col1,col2 FROM test WHERE int_col=123; 数据库配置规范如果应用使用的是长连接，应用必须具有自动重连的机制，但请避免每执行一个SQL去检查一次DB可用性；如果应用使用的是长连接，应用应该具有连接的TIMEOUT检查机制，及时回收长时间没有使用的连接，TIMEOUT时间一般建议为2小时；程序访问数据库连接的字符集请设置为utf8mb4；程序中禁止一切DDL操作。禁止使用应用程序配置文件内的帐号手工访问线上数据库，大部分配置文件内的数据库配置的是主库，你无法预知你的一条SQL会不会导致MySQL崩溃；突发性大量操作数据库等操作时，需进行流量评估，避免数据库出现瓶颈；批量清洗数据，应避开业务高峰期时段执行，并在执行过程中观察服务状态；禁止在主库上执行后台管理和统计类的功能查询，这种复杂类的SQL会造成CPU的升高，进而会影响业务。 常用字段数据类型范围 数值 取值范围 TINYINT(4) -128 ~ 127 TINYINT(4) UNSIGNED 0 ~ 255 SMALLINT(6) -32768 ~ 32767 SMALLINT(6) UNSIGNED 0 ~ 65535 MEDIUMINT(8) -8388608 ~ 8388607 MEDIUMINT(8) UNSIGNED 0 ~ 16777215 INT(11) -2147483648 ~ 2147483647 INT(11) UNSIGNED 0 ~ 4294967295 BIGINT(20) -9223372036854775808 ~ 9223372036854775807 BIGINT(20) UNSIGNED 0 ~ 18446744073709551615 VARCHAR(N)：在MySQL数据库中，VARCHAR(N)中的N代表N个字符，不管你是中文字符还是英文字符，VARCHAR(N)能存储最大为N个中文字符/英文字符。TIMESTAMP: 1970-01-01 00:00:01 UTC ~2038-01-19 03:14:07 UTCDATETIME: 1000-01-0100:00:00 ~ 9999-12-31 23:59:59 参考文献为什么InnoDB表要建议用自增列做主键","categories":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"mysql关键字执行顺序","slug":"mysql关键字执行顺序","date":"2019-11-03T12:32:30.000Z","updated":"2019-11-04T07:47:58.126Z","comments":true,"path":"2019/11/03/mysql关键字执行顺序/","link":"","permalink":"http://aemonswift.github.io/2019/11/03/mysql%E5%85%B3%E9%94%AE%E5%AD%97%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/","excerpt":"","text":"SQL关键字执行顺序 from join on where group by(开始使用select中的别名，后面的语句中都可以使用) avr,sum…等函数 having select distinct order by limit 所有的 查询语句都是从from开始执行的，在执行过程中，每个步骤都会为下一个步骤生成一个虚拟表，这个虚拟表将作为下一个执行步骤的输入。 首先对from子句中的前两个表执行一个笛卡尔乘积，此时生成虚拟表 vt1（选择相对小的表做基础表） 接下来便是应用on筛选器，on 中的逻辑表达式将应用到 vt1 中的各个行，筛选出满足on逻辑表达式的行，生成虚拟表 vt2 如果是outer join 那么这一步就将添加外部行，left outer jion 就把左表在第二步中过滤的添加进来，如果是right outer join 那么就将右表在第二步中过滤掉的行添加进来，这样生成虚拟表 vt3 如果 from 子句中的表数目多余两个表，那么就将vt3和第三个表连接从而计算笛卡尔乘积，生成虚拟表，该过程就是一个重复1-3的步骤，最终得到一个新的虚拟表 vt3。 用where筛选器，对上一步生产的虚拟表引用where筛选器，生成虚拟表vt4。这里存在一个问题。$\\color{red}{对于包含outer join子句的查询，就有一个让人感到困惑的问题，到底在on筛选器还是用where筛选器指定逻辑表达式呢？on和where的最大区别在于，如果在on应用逻辑表达式那么在第三步outer join中还可以把移除的行再次添加回来，而where的移除的最终的。}$例如：有一个学生表（班级,姓名）和一个成绩表(姓名,成绩)，我现在需要返回一个x班级的全体同学的成绩，但是这个班级有几个学生缺考，也就是说在成绩表中没有记录。为了得到我们预期的结果我们就需要在on子句指定学生和成绩表的关系（学生.姓名=成绩.姓名）那么我们是否发现在执行第二步的时候，对于没有参加考试的学生记录就不会出现在vt2中，因为他们被on的逻辑表达式过滤掉了,但是我们用left outer join就可以把左表（学生）中没有参加考试的学生找回来，因为我们想返回的是x班级的所有学生，如果在on中应用学生.班级=’x’的话，left outer join会把x班级的所有学生记录找回，所以只能在where筛选器中应用学生.班级=’x’ 因为它的过滤是最终的。 group by 子句将中的唯一的值组合成为一组，得到虚拟表vt5。如果应用了group by，那么后面的所有步骤都只能得到的vt5的列或者是聚合函数（count、sum、avg等）。原因在于最终的结果集中只为每个组包含一行。(这一步开始才可以使用select中的别名，他返回的是一个游标，而不是一个表，所以在where中不可以使用select中的别名，而having却可以使用) 应用cube或者rollup选项，为vt5生成超组，生成vt6. 应用having筛选器，生成vt7。having筛选器是第一个也是为唯一一个应用到已分组数据的筛选器。 处理select子句。将vt7中的在select中出现的列筛选出来。生成vt8. 应用distinct子句，vt8中移除相同的行，生成vt9。事实上如果应用了group by子句那么distinct是多余的，原因同样在于，分组的时候是将列中唯一的值分成一组，同时只为每一组返回一行记录，那么所以的记录都将是不相同的。 应用order by子句。按照order_by_condition排序vt9，此时返回的一个游标，而不是虚拟表。sql是基于集合的理论的，集合不会预先对他的行排序，它只是成员的逻辑集合，成员的顺序是无关紧要的。对表进行排序的查询可以返回一个对象，这个对象包含特定的物理顺序的逻辑组织。这个对象就叫游标。正因为返回值是游标，那么使用order by 子句查询不能应用于表表达式。排序是很需要成本的，除非你必须要排序，否则最好不要指定order by，最后，在这一步中是第一个也是唯一一个可以使用select列表中别名的步骤。 应用top选项。此时才返回结果给请求者即用户。","categories":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"数据库/SQL","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQL","slug":"SQL","permalink":"http://aemonswift.github.io/tags/SQL/"}]},{"title":"数据库之分库分表","slug":"数据库之分库分表","date":"2019-11-01T23:38:20.000Z","updated":"2019-11-04T00:48:38.217Z","comments":true,"path":"2019/11/02/数据库之分库分表/","link":"","permalink":"http://aemonswift.github.io/2019/11/02/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B9%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/","excerpt":"","text":"为什么要分库分表就是跟着你的公司业务发展走的，你公司业务发展越好，用户就越多，数据量越大，请求量越大，那你单个数据库一定扛不住。 分表(主要为了sql查询速度)比如你单表都几千万数据了，你确定你能扛住么？绝对不行，单表数据量太大，会极大影响你的 sql 执行的性能，到了后面你的 sql 可能就跑的很慢了。一般来说，就以我的经验来看，单表到几百万的时候，性能就会相对差一些了，你就得分表了。分表是啥意思？就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户 id 来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就好了。这样可以控制每个表的数据量在可控的范围内，比如每个表就固定在 200 万以内。 分库(主要为了并发度和磁盘使用情况)分库是啥意思？就是你一个库一般我们经验而言，最多支撑到并发 2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒 1000 左右，不要太大。那么你可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。*||:-:|:-:|:-:并发支撑情况|MySQL 单机部署，扛不住高并发| MySQL从单机到多机，能承受的并发增加了多倍磁盘使用情况| MySQL 单机磁盘容量几乎撑满| 拆分为多个库，数据库服务器磁盘使用率大大降低SQL 执行性能| 单表数据量太大，SQL 越跑越慢| 单表数据量减少，SQL 执行效率明显提升","categories":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分库分表","slug":"数据库/分库分表","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分库分表","slug":"分库分表","permalink":"http://aemonswift.github.io/tags/%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8/"}]},{"title":"数据库SQL分析工具","slug":"数据库sql分析工具","date":"2019-11-01T08:03:43.000Z","updated":"2019-11-01T08:50:08.603Z","comments":true,"path":"2019/11/01/数据库sql分析工具/","link":"","permalink":"http://aemonswift.github.io/2019/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93sql%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"主要是用explain工具来分析sql命中的情况 explain之type字段官网描述为连接类型(the join type)。它描述了找到所需数据使用的$\\color{red}{扫描方式。}$常见的扫描方式如下： system：系统表，少量数据，往往不需要进行磁盘IO； const：常量连接； eq_ref：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描； ref：非主键非唯一索引等值扫描； range：范围扫描； index：索引树扫描； ALL：全表扫描(full table scan)；上面扫描方式由快到慢顺序：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; ALL system ——不需要走io从系统库mysql的系统表time_zone里查询数据，扫码类型为system，这些数据已经加载到内存里，不需要进行磁盘IO。 explain select * from mysql.time_zone;内层嵌套(const)返回了一个临时表，外层嵌套从临时表查询，其扫描类型也是system，也不需要走磁盘IO，速度超快。 explain select * from (select * from user where id=1) tmp; const成为const扫描的条件：且关系 命中主键(primary key)或者唯一(unique)索引； 被连接的部分是一个常量(const)值；例如：explain select * from user where id=1;id是PK，连接部分是常量1。这类扫描效率极高，返回数据量少，速度非常快。 eq_refeq_ref扫描的条件为：对于前表的每一行(row)，后表只有一行被扫描。再细化一点： join查询； 命中主键(primary key)或者非空唯一(unique not null)索引； 等值连接；例如： explain select * from user,user_ex where user.id=user_ex.id; refeq_ref案例中的主键索引，改为普通非唯一(non unique)索引。explain select * from user,user_ex where user.id=user_ex.id;就由eq_ref降级为了ref，此时对于前表的每一行(row)，后表可能有多于一行的数据被扫描。explain select * from user where id=1;当id改为普通非唯一索引后，常量的连接查询，也由const降级为了ref，因为也可能有多于一行的数据被扫描。ref扫描，可能出现在join里，也可能出现在单表普通索引里，每一次匹配可能有多行数据返回，虽然它比eq_ref要慢，但它仍然是一个很快的join类型。 rangerange扫描就比较好理解了，它是索引上的范围查询，它会在索引上扫码特定范围内的值。 123explain select * from user where id between 1 and 4;explain select * from user where idin(1,2,3);explain select * from user where id&gt;3; 像上例中的between，in，&gt;都是典型的范围(range)查询。 indexindex类型，需要扫描索引上的全部数据。explain count (*) from user;id是主键，该count查询需要通过扫描索引上的全部数据来计数。 allexplain select * from user,user_ex where user.id=user_ex.id;如果id上不建索引，对于前表的每一行(row)，后表都要被全表扫描。 注意事项“列类型”与“where值类型”不符，不能命中索引，会导致全表扫描(full table scan)。12345create table t1 (cell varchar(3) primary key)engine=innodb default charset=latin1;insert into t1(cell) values ('111'),('222'),('333'); explain select * from t1 where cell=111;强制类型转换，不能命中索引，需要全表扫描，即3条记录(即explain中的rows字段)；explain select * from t1 where cell=&#39;111&#39;;类型相同，命中索引，1条记录；(即explain中的rows字段) 相join的两个表的字符编码不同，不能命中索引，会导致笛卡尔积的循环计算（nested loop）。1234567891011121314151617create table t1 (cell varchar(3) primary key)engine=innodb default charset=utf8;insert into t1(cell) values ('111'),('222'),('333');create table t2 (cell varchar(3) primary key)engine=innodb default charset=latin1;insert into t2(cell) values ('111'),('222'),('333'),('444'),('555'),('666');create table t3 (cell varchar(3) primary key)engine=innodb default charset=utf8;insert into t3(cell) values ('111'),('222'),('333'),('444'),('555'),('666'); t2和t1字符集不同，插入6条测试数据； t3和t1字符集相同，也插入6条测试数据； 除此之外，t1，t2，t3表结构完全相同；explain select * from t1,t2 where t1.cell=t2.cell;第一个join，连表t1和t2（字符集不同），关联属性是cell； explain select * from t1,t3 where t1.cell=t3.cell;第一个join，连表t1和t3（字符集相同），关联属性是cell；测试结果： t1和t2字符集不同，存储空间不同； t1和t2相join时，遍历了t1的所有记录3条，t1的每一条记录又要遍历t2的所有记录6条，实际进行了笛卡尔积循环计算(nested loop)，索引无效； ）t1和t3相join时，遍历了t1的所有记录3条，t1的每一条记录使用t3索引，即扫描1行记录；参考文献两类非常隐蔽的全表扫描，不能命中索引","categories":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分析工具","slug":"数据库/分析工具","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"分析工具","slug":"分析工具","permalink":"http://aemonswift.github.io/tags/%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"}]},{"title":"数据库索引原理","slug":"数据库索引原理","date":"2019-11-01T03:03:44.000Z","updated":"2019-11-04T00:48:38.218Z","comments":true,"path":"2019/11/01/数据库索引原理/","link":"","permalink":"http://aemonswift.github.io/2019/11/01/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86/","excerpt":"","text":"数据库为什么要选择B+树作为索引 数据库为什么需要索引 数据库存储了1000W条数据，要从中找到name=”shenjian”的记录，一条条查，要查到什么时候去？于是，$\\color{red}{要有索引，用于提升数据库的查找速度。}$ 哈希(hash)比树(tree)更快，索引结构为什么要设计成树型？加速查找速度的数据结构，常见的有两类： 哈希，例如HashMap，查询/插入/修改/删除的平均时间复杂度都是O(1)； 树，例如平衡二叉搜索树，查询/插入/修改/删除的平均时间复杂度都是O(lg(n))；可以看到，不管是读请求，还是写请求，哈希类型的索引，都要比树型的索引更快一些，那为什么，索引结构要设计成树型呢？索引设计成树形，和SQL的需求相关。select * from t where name=”shenjian”，确实是哈希索引更快，因为每次都只查询一条记录。但是对于排序查询的SQL需求：分组（group by），排序（order by），比较（&gt;,&lt;）等，哈希型的索引，时间复杂度会退化为O(n)，而树型的“有序”特性，依然能够保持O(log(n)) 的高效率。 常见的树二叉树当数据量大的时候，树的高度会比较高，数据量大的时候，查询会比较慢；每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO； B树特点：a. 不再是二叉搜索，而是m叉搜索；b. 叶子节点，非叶子节点，都存储数据；c. 中序遍历，可以获得所有节点；B树被作为实现索引的数据结构被创造出来，是因为它能够完美的利用“局部性原理”。(所谓局部性原理：1. 内存读写块，磁盘读写慢，而且慢很多；2. 磁盘预读：磁盘读写并不是按需读取，而是按页预读，一次会读一页的数据，每次加载更多的数据，如果未来要读取的数据就在这一页中，可以避免未来的磁盘IO，提高效率；3. 局部性原理：软件设计要尽量遵循“数据读取集中”与“使用到一个数据，大概率会使用其附近的数据”，这样磁盘预读能充分提高磁盘IO；)B树为何适合做索引：1. 由于是m分叉的，高度能够大大降低；2. 每个节点可以存储j个记录，如果将节点大小设置为页大小，例如4K，能够充分的利用预读的特性，极大减少磁盘IO； B+树仍是m叉搜索树，在B树的基础上，做了一些改进： 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上；（B+树中根到每一个节点的路径长度一样，而B树不是这样。） 叶子之间，增加了链表，获取所有节点，不再需要中序遍历；与B树相比，优势： 范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯； 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储； 非叶子节点，不存储实际记录，而只存储记录的KEY的话，那么在相同内存的情况下，B+树能够存储更多索引；选择B+树的原因 数据库索引用于加速查询 虽然哈希索引是O(1)，树索引是O(log(n))，但SQL有很多“有序”需求，故数据库使用树型索引 数据预读的思路是：磁盘读写并不是按需读取，而是按页预读，一次会读一页的数据，每次加载更多的数据，以便未来减少磁盘IO 局部性原理：软件设计要尽量遵循“数据读取集中”与“使用到一个数据，大概率会使用其附近的数据”，这样磁盘预读能充分提高磁盘IO 很低的树高度，能够存储大量数据； 索引本身占用的内存很小； 能够很好的支持单点查询，范围查询，有序性查询； InnoDB不支持哈希索引 聚集索引与非聚集索引 非聚集索引：索引与行记录是分开存储的 聚集索引：主键索引与行记录是存储在一起的 MyISAM索引其主键索引与普通索引没有本质差异：（MyISAM的表可以没有主键。） 有连续聚集的区域单独存储行记录 主键索引的叶子节点，存储主键和对应行记录的指针 普通索引的叶子结点，存储索引列和对应行记录的指针 InnoDB索引InnoDB必须要有聚集索引，行记录按照聚集索引物理上排序。必须要有聚集索引，并不代表一定要有主键。InnoDB的主键索引与行记录是存储在一起的， 没有单独区域存储行记录 主键索引的叶子节点，存储主键和对应行记录（而不是指针）因此，InnoDB的PK查询是非常快的。因为这个特性，InnoDB必须有聚集索引： 如果表定义了主键，则PK就是聚集索引； 如果没有主键被定义，那么该表的第一个唯一非空索引被作为聚集索引。 如果没有主键也没有合适的唯一索引，那么innodb内部会生成一个隐藏的主键作为聚集索引，这个隐藏的主键是一个6个字节的列，该列的值会随着数据的插入自增。聚集索引，也只能够有一个，因为数据行在物理磁盘上只能有一份聚集存储。InnoDB的普通索引可以有多个，它与聚集索引是不同的： 普通索引的叶子节点，存储索引列和主键（也不是指针）对于InnoDB表，这里的启示是： 不建议使用较长的列做主键，例如char(64)，因为所有的普通索引都会存储主键，会导致普通索引过于庞大； 建议使用趋势递增的key做主键，由于数据行与索引一体，这样不至于插入记录时，有大量索引分裂，行记录移动； 主键的选择 不能为空的列 不能重复的列 很少改变的列：行是按照聚集索引物理排序的，如果主键频繁改变，物理顺序会改变，性能会急剧降低。 经常被检索的列：被检索的列上要建立索引，如果该索引是聚集索引，能够避免回表，性能提升几乎一倍。 不是太长的列：普通索引叶子节点会存储主键值，如果主键值太长，会增加普通索引的大小。 主键和聚集索引的区别 InnoDB一定会存在聚集索引的，故建立表的时候可以没有主键，其聚集索引如何选择，见上述描述。 建立表时若不声明主键非空，InnoDB会自动添加非空(not null)且唯一(unique)的限制。123456789101112131415(1) create table user( id int, name varchar(10), primary key(id))engine=innodb;(2) insert into user(name) values('shenjian');(3) insert into user(name) values('shenjian');#执行第三行的时候会报错，产生主键冲突# 执行show create table命令查看表时，发现表结构为：create table user( id int(11) NOT NULL DEFAULT '0', name varchar(10) DEFAULT NULL, primary key(id))engine=innodb; 建立表的时候，可以选择多个字段作为主键——只要满足聚集索引的要求即可。 建立表的时候可以单独使用自增主键，插入记录的时候也可以插入主键id（但要保证主键不能冲突） 建立表的时候使用联合自增主键时注意设置主键的顺序——必须保证自增主键在第一列。123456create table user( id int(11) NOT NULL DEFAULT '0' auto_increment, name varchar(10) DEFAULT NULL, primary key(name,id), #使用这个主键，建表将会报错 primary key(id,name), # 使用此主键，建表正确（必须保证自增主键在第一列）)engine=innodb; 例如：select * from t where name=‘lisi’;会先通过name辅助索引定位到B+树的叶子节点得到id=5，再通过聚集索引定位到行记录。——扫描列两次索引树。如何解决扫描两次索引树得到结果？——索引覆盖 索引覆盖$\\color{red}{索引覆盖：}$只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。使用explain查询sql命中的索引时，即explain的输出结果Extra字段为Using index时，能够触发索引覆盖。解决方法：建立两列以上的索引，查询复合索引里的列的数据不需要进行回表二次查询，如index(col1, col2)，执行下面的语句：(主键id可以例外：因为叶子节点存储了索引列和主键id)select col1, col2 from t1 where col1 = &#39;213&#39;; 哪些场景可以利用索引覆盖来优化SQL？ 全表count查询优化 select count(name) from user,只要name可以进行索引，就会输出结果Extra字段为Using index（索引覆盖） 列查询回表优化——将单列索引(name)升级为联合索引(name, sex)，即可避免回表。select id,name,sex ... where name=&#39;shenjian&#39;; 分页查询。select id,name,sex ... order by name limit 500,100;将单列索引(name)升级为联合索引(name, sex)，也可以避免回表。 参考文献1分钟了解MyISAM与InnoDB的索引差异数据库索引，到底是什么做的？Mysql的聚集索引与辅助索引如何避免回表查询？什么是索引覆盖？","categories":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"索引","slug":"数据库/索引","permalink":"http://aemonswift.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/%E7%B4%A2%E5%BC%95/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://aemonswift.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"索引","slug":"索引","permalink":"http://aemonswift.github.io/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"布谷鸟过滤器","slug":"布谷鸟过滤器","date":"2019-11-01T02:38:18.000Z","updated":"2019-11-01T02:53:43.404Z","comments":true,"path":"2019/11/01/布谷鸟过滤器/","link":"","permalink":"http://aemonswift.github.io/2019/11/01/%E5%B8%83%E8%B0%B7%E9%B8%9F%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"为了解决布隆过滤器不能删除元素的问题，布谷鸟过滤器横空出世。相比布谷鸟过滤器而言布隆过滤器有以下不足：查询性能弱、空间利用效率低、不支持反向操作（删除）以及不支持计数。查询性能弱是因为布隆过滤器需要使用多个 hash 函数探测位图中多个不同的位点，这些位点在内存上跨度很大，会导致 CPU 缓存行命中率低。空间效率低是因为在相同的误判率下，布谷鸟过滤器的空间利用率要明显高于布隆，空间上大概能节省 40% 多。不过布隆过滤器并没有要求位图的长度必须是 2 的指数，而布谷鸟过滤器必须有这个要求。从这一点出发，似乎布隆过滤器的空间伸缩性更强一些。不支持反向删除操作这个问题着实是击中了布隆过滤器的软肋。在一个动态的系统里面元素总是不断的来也是不断的走。布隆过滤器就好比是印迹，来过来就会有痕迹，就算走了也无法清理干净。比如你的系统里本来只留下 1kw 个元素，但是整体上来过了上亿的流水元素，布隆过滤器很无奈，它会将这些流失的元素的印迹也会永远存放在那里。随着时间的流失，这个过滤器会越来越拥挤，直到有一天你发现它的误判率太高了，不得不进行重建。 但布谷鸟过滤器它支持的反向删除操作非常鸡肋，以至于你根本没办法使用这个功能。 布谷鸟哈希算法原理布谷鸟过滤器源于布谷鸟哈希算法，布谷鸟哈希算法源于生活 —— 那个热爱「鸠占鹊巢」的布谷鸟。布谷鸟喜欢滥交（自由），从来不自己筑巢。它将自己的蛋产在别人的巢里，让别人来帮忙孵化。待小布谷鸟破壳而出之后，因为布谷鸟的体型相对较大，它又将养母的其它孩子（还是蛋）从巢里挤走 —— 从高空摔下夭折了。最简单的布谷鸟哈希结构是一维数组结构，会有两个 hash 算法将新来的元素映射到数组的两个位置。如果两个位置中有一个位置为空，那么就可以将元素直接放进去。但是如果这两个位置都满了，它就不得不「鸠占鹊巢」，随机踢走一个，然后自己霸占了这个位置。不同于布谷鸟的是，布谷鸟哈希算法会帮这些受害者（被挤走的蛋）寻找其它的窝。因为每一个元素都可以放在两个位置，只要任意一个有空位置，就可以塞进去。所以这个伤心的被挤走的蛋会看看自己的另一个位置有没有空，如果空了，自己挪过去也就皆大欢喜了。但是如果这个位置也被别人占了呢？好，那么它会再来一次「鸠占鹊巢」，将受害者的角色转嫁给别人。然后这个新的受害者还会重复这个过程直到所有的蛋都找到了自己的巢为止。但是会遇到一个问题，那就是如果数组太拥挤了，连续踢来踢去几百次还没有停下来，这时候会严重影响插入效率。这时候布谷鸟哈希会设置一个阈值，当连续占巢行为超出了某个阈值，就认为这个数组已经几乎满了。这时候就需要对它进行扩容，重新放置所有元素。还会有另一个问题，那就是可能会存在挤兑循环。比如两个不同的元素，hash 之后的两个位置正好相同，这时候它们一人一个位置没有问题。但是这时候来了第三个元素，它 hash 之后的位置也和它们一样，很明显，这时候会出现挤兑的循环。不过让三个不同的元素经过两次 hash 后位置还一样，这样的概率并不是很高，除非你的 hash 算法太差了。布谷鸟哈希算法对待这种挤兑循环的态度就是认为数组太拥挤了，需要扩容（实际上并不是这样）。 布谷鸟哈希算法优化上面的布谷鸟哈希算法的平均空间利用率并不高，大概只有 50%。到了这个百分比，就会很快出现连续挤兑次数超出阈值。这样的哈希算法价值并不明显，所以需要对它进行改良。改良的方案之一是增加 hash 函数，让每个元素不止有两个巢，而是三个巢、四个巢。这样可以大大降低碰撞的概率，将空间利用率提高到 95%左右。另一个改良方案是在数组的每个位置上挂上多个座位，这样即使两个元素被 hash 在了同一个位置，也不必立即「鸠占鹊巢」，因为这里有多个座位，你可以随意坐一个。除非这多个座位都被占了，才需要进行挤兑。很明显这也会显著降低挤兑次数。这种方案的空间利用率只有 85%左右，但是查询效率会很高，同一个位置上的多个座位在内存空间上是连续的，可以有效利用 CPU 高速缓存。所以更加高效的方案是将上面的两个改良方案融合起来，比如使用 4 个 hash 函数，每个位置上放 2 个座位。这样既可以得到时间效率，又可以得到空间效率。这样的组合甚至可以将空间利用率提到高 99%，这是非常了不起的空间效率。 实现方案假设有一段文本数据，我们把它通过cuckoo filter导入到一个虚拟的flash中，再把它导出到另一个文本文件中。flash存储的单元页面是一个log_entry，里面包含了一对key/value，value就是文本数据，key就是这段大小的数据的SHA1值（照理说SHA1是可以通过数据源生成，没必要存储到flash，但这里主要为了测试而故意设计的，万一key和value之间没有推导关系呢）。 123456789#define SECTOR_SIZE (1 &lt;&lt; 10)#define DAT_LEN (SECTOR_SIZE - 20) /* 减去20主要是为了给sha1使用*//* The log entries store key-value pairs on flash and the * size of each entry is assumed just one sector fit. */struct log_entry &#123; uint8_t sha1[20]; uint8_t data[DAT_LEN];&#125;; 顺便说明一下DAT_LEN设置，之前我们设计了一个虚拟flash（用malloc模拟出来），由于flash的单位是按页大小SECTOR_SIZE读写，这里假设每个log_entry正好一个页大小，当然可以根据实际情况调整。至于哈希表里的slot有三个成员tag，status和offset，分别是哈希值，状态值和在flash的偏移位置。其中status有三个枚举值：AVAILIBLE，OCCUPIED，DELETED，分别表示这个slot是空闲的，占用的还是被删除的。$\\color{red}{至于tag，按理说应该有两个哈希值，对应两个哈希函数，但其中一个已经对应bucket的位置上了，所以我们只要保存另一个备用bucket的位置就行了}$，这样万一被踢，只要用这个tag就可以找到它的另一个安身之所。 12345678910enum &#123; AVAILIBLE, OCCUPIED, DELETED, &#125;; /* The in-memory hash bucket cache is to filter keys (which is assumed SHA1) via * cuckoo hashing function and map keys to log entries stored on flash. */struct hash_slot_cache &#123; uint32_t tag : 30; /* summary of key */ uint32_t status : 2; /* FSM */ uint32_t offset; /* offset on flash memory */&#125;; 乍看之下size有点大是吗？没关系，你也可以根据情况调整数据类型大小，比如uint16_t，这里仅仅为了测试正确性。至于哈希表以及bucket和slot的创建见初始化代码。buckets是一个二级指针，每个bucket指向4个slot大小的缓存，即4路slot，那么bucket_num也就是slot_num的1/4。这里我们故意把slot_num调小了点，为的是测试rehash的发生。 1234567891011121314151617181920212223242526272829303132#define ASSOC_WAY (4) /* 4-way association */ struct hash_table &#123; struct hash_slot_cache **buckets; struct hash_slot_cache *slots; uint32_t slot_num; uint32_t bucket_num;&#125;; int cuckoo_filter_init(size_t size)&#123; ... /* Allocate hash slots */ hash_table.slot_num = size / SECTOR_SIZE; /* Make rehashing happen */ hash_table.slot_num /= 4; hash_table.slots = calloc(hash_table.slot_num, sizeof(struct hash_slot_cache)); if (hash_table.slots == NULL) &#123; return -1; &#125; /* Allocate hash buckets associated with slots */ hash_table.bucket_num = hash_table.slot_num / ASSOC_WAY; hash_table.buckets = malloc(hash_table.bucket_num * sizeof(struct hash_slot_cache *)); if (hash_table.buckets == NULL) &#123; free(hash_table.slots); return -1; &#125; for (i = 0; i &lt; hash_table.bucket_num; i++) &#123; hash_table.buckets[i] = &amp;hash_table.slots[i * ASSOC_WAY]; &#125;&#125; 下面是哈希函数的设计，这里有两个，前面提到既然key是20字节的SHA1值，我们就可以分别是对key的低32位和高32位进行位运算，只要bucket_num满足2的幂次方，我们就可以将key的一部分同bucket_num – 1相与，就可以定位到相应的bucket位置上，注意bucket_num随着rehash而增大，哈希函数简单的好处是求哈希值十分快。 12#define cuckoo_hash_lsb(key, count) (((size_t *)(key))[0] &amp; (count - 1))#define cuckoo_hash_msb(key, count) (((size_t *)(key))[1] &amp; (count - 1)) 终于要讲解cuckoo filter最重要的三个操作了——查询、插入还有删除。查询操作是简单的，我们对传进来的参数key进行两次哈希求值tag[0]和tag[1]，并先用tag[0]定位到bucket的位置，从4路slot中再去对比tag[1]。只有比中了tag后，由于只是key的一部分，我们再去从flash中验证完整的key，并把数据在flash中的偏移值read_addr输出返回。相应的，如果bucket[tag[0]]的4路slot都没有比中，我们再去bucket[tag[1]]中比对（代码略），如果还比不中，可以肯定这个key不存在。$\\color{red}{这种设计的好处就是减少了不必要的flash读操作，每次比对的是内存中的tag而不需要完整的key。} 12345678910111213141516171819202122232425262728static int cuckoo_hash_get(struct hash_table *table, uint8_t *key, uint8_t **read_addr)&#123; int i, j; uint8_t *addr; uint32_t tag[2], offset; struct hash_slot_cache *slot; tag[0] = cuckoo_hash_lsb(key, table-&gt;bucket_num); tag[1] = cuckoo_hash_msb(key, table-&gt;bucket_num); /* Filter the key and verify if it exists. */ slot = table-&amp;gt;buckets[tag[0]]; for (i = 0; i bucket_num) == slot[i].tag) &#123; if (slot[i].status == OCCUPIED) &#123; offset = slot[i].offset; addr = key_verify(key, offset); if (addr != NULL) &#123; if (read_addr != NULL) &#123; *read_addr = addr; &#125; break; &#125; &#125; else if (slot[i].status == DELETED) &#123; return DELETED; &#125; &#125; ...&#125; 接下来先将简单的删除操作，之所以简单是因为delete除了将相应slot的状态值设置一下之外，其实什么都没有干，也就是说它不会真正到flash里面去把数据清除掉。为什么？很简单，没有必要。还有一个原因，flash的写操作之前需要擦除整个页面，这种擦除是会折寿的，$\\color{red}{所以很多flash支持随机读，但必须保持顺序写。}$ 123456789101112131415static void cuckoo_hash_delete(struct hash_table *table, uint8_t *key)&#123; uint32_t i, j, tag[2]; struct hash_slot_cache *slot; tag[0] = cuckoo_hash_lsb(key, table-&gt;bucket_num); tag[1] = cuckoo_hash_msb(key, table-&gt;bucket_num); slot = table-&gt;buckets[tag[0]]; for (i = 0; i bucket_num) == slot[i].tag) &#123; slot[i].status = DELETED; return; &#125; ...&#125; 了解了flash的读写特性，你就知道为啥插入操作在flash层面要设计成append。不过我们这里不讨论过多flash细节，哈希表层面的插入逻辑其实跟查询差不多，我就不贴代码了。这里要贴的是如何判断并处理碰撞，其实这里也没啥玄机，就是用old_tag和old_offset保存一下临时变量，以便一个元素被踢出去之后还能找到备用的安身之所。但这里会有一个判断，每次踢人都会计数，当alt_cnt大于512时候表示哈希表真的快满了，这时候需要rehash了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455static int cuckoo_hash_collide(struct hash_table *table, uint32_t *tag, uint32_t *p_offset)&#123; int i, j, k, alt_cnt; uint32_t old_tag[2], offset, old_offset; struct hash_slot_cache *slot; /* Kick out the old bucket and move it to the alternative bucket. */ offset = *p_offset; slot = table-&gt;buckets[tag[0]]; old_tag[0] = tag[0]; old_tag[1] = slot[0].tag; old_offset = slot[0].offset; slot[0].tag = tag[1]; slot[0].offset = offset; i = 0 ^ 1; k = 0; alt_cnt = 0; KICK_OUT: slot = table-&gt;buckets[old_tag[i]]; for (j = 0; j &lt; ASSOC_WAY; j++) &#123; if (offset == INVALID_OFFSET &amp;&amp; slot[j].status == DELETED) &#123; slot[j].status = OCCUPIED; slot[j].tag = old_tag[i ^ 1]; *p_offset = offset = slot[j].offset; break; &#125; else if (slot[j].status == AVAILIBLE) &#123; slot[j].status = OCCUPIED; slot[j].tag = old_tag[i ^ 1]; slot[j].offset = old_offset; break; &#125; &#125; if (j == ASSOC_WAY) &#123; if (++alt_cnt &gt; 512) &#123; if (k == ASSOC_WAY - 1) &#123; /* Hash table is almost full and needs to be resized */ return 1; &#125; else &#123; k++; &#125; &#125; uint32_t tmp_tag = slot[k].tag; uint32_t tmp_offset = slot[k].offset; slot[k].tag = old_tag[i ^ 1]; slot[k].offset = old_offset; old_tag[i ^ 1] = tmp_tag; old_offset = tmp_offset; i ^= 1; goto KICK_OUT; &#125; return 0;&#125; rehash的逻辑也很简单，无非就是把哈希表中的buckets和slots重新realloc一下，空间扩展一倍，然后再从flash中的key重新插入到新的哈希表里去。这里有个陷阱要注意，千万不能有相同的key混进来！虽然cuckoo hashing不像开链法那样会退化成O(n)，但由于每个元素有两个哈希值，而且每次计算的哈希值随着哈希表rehash的规模而不同，相同的key并不能立即检测到冲突，但当相同的key达到一定规模后，噩梦就开始了，由于rehash里面有插入操作，一旦在这里触发碰撞，又会触发rehash，这时就是一个rehash不断递归的过程，由于其中老的内存没释放，新的内存不断重新分配，整个程序就如同陷入DoS攻击一般瘫痪了。所以每次插入操作前一定要判断一下key是否已经存在过，并且对rehash里的插入使用碰撞断言防止此类情况发生。笔者在测试中不幸中了这样的彩蛋，调试了大半天才搞清楚原因，搞IT的同学们记住一定要防小人啊~ 1234567891011121314151617181920212223static void cuckoo_rehash(struct hash_table *table)&#123; ... uint8_t *read_addr = nvrom_base_addr; uint32_t entries = log_entries; while (entries--) &#123; uint8_t key[20]; uint32_t offset = read_addr - nvrom_base_addr; for (i = 0; i &amp;lt; 20; i++) &#123; key[i] = flash_read(read_addr); read_addr++; &#125; /* Duplicated keys in hash table which can cause eternal * hashing collision! Be careful of that! */ assert(!cuckoo_hash_put(table, key, &amp;offset)); if (cuckoo_hash_get(&amp;old_table, key, NULL) == DELETED) &#123; cuckoo_hash_delete(table, key); &#125; read_addr += DAT_LEN; &#125; ...&#125; 参考文献布隆过滤器过时了，未来属于布谷鸟过滤器？CUCKOO FILTER：设计与实现布隆过滤器实现C++布隆过滤器实现go","categories":[],"tags":[]},{"title":"布隆过滤器","slug":"布隆过滤器","date":"2019-10-31T11:38:18.000Z","updated":"2019-10-31T11:45:54.393Z","comments":true,"path":"2019/10/31/布隆过滤器/","link":"","permalink":"http://aemonswift.github.io/2019/10/31/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"问题假设你现在要处理这样一个问题，你有一个网站并且拥有很多访客，每当有用户访问时，你想知道这个ip是不是第一次访问你的网站。这是一个很常见的场景，为了完成这个功能，你很容易就会想到下面这个解决方案：把访客的ip存进一个hash表中，每当有新的访客到来时，先检查哈希表中是否有改访客的ip，如果有则说明该访客在黑名单中。你还知道，hash表的存取时间复杂度都是O(1),效率很高，因此你对你的方案很是满意。然后我们假设你的网站已经被1亿个用户访问过，每个ip的长度是15，那么你一共需要$15 * 100000000 = 1500000000Bytes = 1.4G$，这还没考虑hash冲突的问题（hash表中的槽位越多，越浪费空间，槽位越少，效率越低）。于是聪明的你稍一思考，又想到可以把ip转换成无符号的int型值来存储，这样一个ip只需要占用4个字节就行了，这时1亿个ip占用的空间是$4 * 100000000 = 400000000Bytes = 380M$，空间消耗降低了很多。那还有没有在不影响存取效率的前提下更加节省空间的办法呢? BitSet32位无符号int型能表示的最大值是4294967295，所有的ip都在这个范围内，我们可以用一个bit位来表示某个ip是否出现过，如果出现过，就把代表该ip的bit位置为1，那么我们最多需要429496729个bit就可以表示所有的ip了。举个例子比如10.0.0.1转换成int是167772161，那么把长度为4294967295的bit数组的第167772161个位置置为1即可，当有ip访问时，只需要检查该标志位是否为1就行了。4294967295bit = 536870912Byte = 512M。如果用hash表示所有4294967295范围内的数组的话，需要十几G的空间。当然，这里举ip的例子不一定合适，主要目的是为了引出BitSet。 实现过程例子：首先，比如我们有一个长度=2的byte数组，2个字节一共有16位，可以表示0-15的数字是否存在。比如我们要验证11是否出现过，那么我们先检查第11个位置是否为1，如果为0，说明11没出现过，然后我们把第11位置为1，表示11已经出现过了。故BitSet基本只有两个操作，set(int value) 和 isHas(int value) set(int value)我们先来看set怎么实现，因为一个byte占8位，所以对于一个给定的value，我们先求出该value应该位于哪个Byte上，这很简单，int byteIndex = value / 8;找到value在byte数组中的位置后，再就是在该字节中寻找表示value的bit位，我们知道，一个byte其实就是一个长为8的bit数组，那么value在该bit数组中的位置也就很好算了，int bitIndex = value % 8;最后我们把该bit位设置为1就可以了：byte[byteIndex] = byte[byteIndex] | 1 &lt;&lt; ( 7 - bitIndex) 12345void set(int value)&#123; int byteIndex = value / 8; int bitIndex = value % 8; byte[byteIndex] = byte[byteIndex] | 1 &lt;&lt; (7 - bitIndex)&#125; isHas(int value)12345bool isHash(int value)&#123; int byteIndex = value / 8; int bitIndex = value % 8; return byte[byteIndex] &amp; 1 &lt;&lt; (7 - bitIndex) &gt; 0&#125; $\\color{red}{例子：}$比如我们有一个长度=2的byte数组，2个字节一共有16位，可以表示0-15的数字是否存在。比如我们要验证11是否出现过，那么我们先检查第11个位置是否为1，如果为0，说明11没出现过，然后我们把第11位置为1，表示11已经出现过了。 BitSet的局限性 当样本分布极度不均匀的时候，BitSet会造成很大空间上的浪费。比如你有10个数，分别是1、2、3、4、5、6、7、8、99999999999；那么你不得不用99999999999个bit位去实现你的BitSet,而这个BitSet的中间绝大多数位置都是0，并且永远不会用到，这显然是极度不划算的. 当元素不是整型的时候，BitSet就不适用了。若你拿到的是一堆url，然后如果你想用BitSet做去重的话，先得把url转换成int型，在转换的过程中难免某些url会计算出相同的int值，于是BitSet的准确性就会降低。那针对这两种情况有没有解决办法呢？第一种分布不均匀的情况可以通过hash函数，将元素都映射到一个区间范围内，减少大段区间闲置造成的浪费，这很简单，取模就好了，难的是取模之后的值保证不相同，即不发生hash冲突。第二种情况，把字符串映射成整数是必要的，那么唯一要做的就是保证我们的hash函数尽可能的减少hash冲突，一次不行我就多hash几次，hash还是容易碰撞，那我就扩大数组的范围，使hash值尽可能的均匀分布，减少hash冲突的概率。基于这种思想，BloomFilter诞生了。 布隆过滤器本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。 核心思想 多个hash，增大随机性，减少hash碰撞的概率 扩大数组范围，使hash值均匀分布，进一步减少hash碰撞的概率。 底层数据结构布隆过滤器是一个 bit 向量或者说 bit 数组。例如：你有10个Url，你完全可以创建一长度是100bit的数组，然后对url分别用5个不同的hash函数进行hash，得到5个hash后的值，这5个值尽可能的保证均匀分布在100个bit的范围内。然后把5个hash值对应的bit位都置为1，判断一个url是否已经存在时，一次看5个bit位是否为1就可以了，如果有任何一个不为1，那么说明这个url不存在。$\\color{red}{这里需要注意的是，如果对应的bit位值都为1，那么也不能肯定这个url一定存在，这个是BloomFilter的特点之一。}$ BloomFilter的实践 黑名单。比如邮件黑名单过滤器，判断邮件地址是否在黑名单中 排序(仅限于BitSet)。仔细想想，其实BitSet在set(int value)的时候，“顺便”把value也给排序了。 网络爬虫。判断某个URL是否已经被爬取过 K-V系统快速判断某个key是否存在。典型的例子有Hbase，Hbase的每个Region中都包含一个BloomFilter，用于在查询时快速判断某个key在该region中是否存在，如果不存在，直接返回，节省掉后续的查询。 利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。 既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。 大Value拆分Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。 BloomFilter的准确性——hash函数个数以及bit向量长度的选择问题从直观上看，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。 分析hash函数个数以隆过滤器长度的选择指导假设： k为hash函数个数 m为布隆过滤器长度 n插入元素的个数 p为误报率 $$m=-\\frac{nlnp}{(ln2)^2}$$$$k=\\frac{m}{n}ln2$$假设哈希函数以相等的概率选择每个数组位置。如果m是数组长度，则哈希函数未将某个位置置为1的概率为：$1-\\frac{1}{m}$。假设k是哈希函数的数量，并且每个散列函数之间没有显着相关性，则该位置未被任何哈希函数设置为1的概率为：$(1-\\frac{1}{m})^k$。如果我们插入了n个元素，此位置仍然为0的概率为：$(1-\\frac{1}{m})^{kn}$，故为1的概率为：$1-(1-\\frac{1}{m})^{kn}$。k个哈希函数都将此位置置为1的概率为：$p=(1-(1-\\frac{1}{m})^{kn})^k$。p也就是我们的误差率，我们需要最小化p值。$$p=(1-(1-\\frac{1}{m})^{kn})^k\\approx (1-e^{\\frac{-kn}{m}})^k $$我们先给定m,n的值，求导后得出：$$k=\\frac{m}{n}ln2$$再将求出的k值带入p的表达式中，得：$$p=(1-e^{\\frac{m}{n}ln2\\frac{n}{m}})^{\\frac{m}{n}ln2}$$进一步有：$$lnp=-\\frac{m}{n}(ln2)^2$$从而得到：$$m=-\\frac{nlnp}{(ln2)^2}$$ 参考文献布隆过滤器详解布隆过滤器的原理、使用场景和注意事那些惊艳的算法们（一）——布隆过滤器bloom filter与Cuckoo Filter布谷鸟过滤器","categories":[],"tags":[]},{"title":"人生bug之地","slug":"人生bug之地","date":"2019-10-29T00:23:09.000Z","updated":"2019-10-29T06:48:23.588Z","comments":true,"path":"2019/10/29/人生bug之地/","link":"","permalink":"http://aemonswift.github.io/2019/10/29/%E4%BA%BA%E7%94%9Fbug%E4%B9%8B%E5%9C%B0/","excerpt":"","text":"bug引入时间2019年10月27日，毕业半年多，第一次写了人生第一个bug。由于修改了别人的代码：其它服务调用此接口时会发生记录信息丢失问题，以致于线上出现了部分属性信息丢失原因。 1234567891011121314151617181920212223242526272829func (d *Dao) UpdateChannelInfo(ctx context.Context, req *v1.UpdateChannelInfoReq) (int64, error) &#123; var ( _updateChannelInfo = \"update channel set \" field []string args []interface&#123;&#125; ) if req.Name != \"\" &#123; field = append(field, \"name=? \") args = append(args, req.Name) &#125; field = append(field, \" Background=?\") //引入bug，去掉了Background不为\"\"的判断 args = append(args, req.Background) if req.Latest != 0 &#123; field = append(field, \" latest=? \") args = append(args, req.Latest) &#125; field = append(field, \" alpha=?\") args = append(args, req.Alpha) if len(args) == 0 &#123; return 0, nil &#125; args = append(args, req.Cid) res, err := d.db.Exec(ctx, _updateChannelInfo+strings.Join(field, \",\")+\" where cid=? ;\", args...) if err != nil &#123; log.Error(\"d.db.Exec() error(%v)\", err) return 0, err &#125; return res.LastInsertId()&#125; bug的原因此接口调用未考虑到有一方调用——只修改Latest属性是另外一个服务来调用；其它属性的修改又是一个服务来调用。由于自己的疏忽，未考虑到此接口供多方服务来进行调用——只修改Latest属性的调用把Background和alpha都置为0. 潜在的bug若对入参数进行这样设置： 123456789message UpdateChannelInfoReq &#123; int64 cid = 1 [(gogoproto.moretags) = \"form:\\\"cid\\\" validate:\\\"required,min=1\\\"\"]; string name = 2 [(gogoproto.moretags) = \"form:\\\"name\\\"\"]; string icon = 3 [(gogoproto.moretags) = \"form:\\\"icon\\\"\"]; string color = 4 [(gogoproto.moretags) = \"form:\\\"color\\\"\"]; string background = 5 [(gogoproto.moretags) = \"form:\\\"background\\\"\"]; int64 latest = 6 [(gogoproto.jsontag) = \"latest\", (gogoproto.casttype) = \"go-common/library/time.Time\"]; int32 alpha=7 [(gogoproto.moretags) = \"form:\\\"alpha\\\" validate=\\\"gt=0\\\"\"];&#125; 出现如下问题：有一方服务想修改Latest属性，会一直发生请求错误。因为：alpha参数属性是必须大于0的。特别是job服务很难进行排查。 如何避免类似问题 设计写接口的时候，尽量做到功能单一，且做到一个写接口只给一个服务方来调用。例如：上面只修改属性可以拆成一个接口；其它属性修改拆成另外一个接口。 测试要认真：一定要从线上，预发，以及线上灰度上面认真测试，特别是修改别人代码的接口（修改一行也要测），以及关注mysql的qps（防止接口中写入慢查询），日志的错误信息（防止请求错误过多，例如上述的参数校验导致了更新Latest属性的接口一直请求错误）。 数据库里面的数据一定要进行每日备份，错误怎么避免都会犯错的，但最坏打算就是恢复数据。 测试修改别人代码的接口时候，一定要先把之前记录copy出来，然后进行修改，进行对比，特别是线上更需要进行对比（经过大约三四个小时，再去对比几次）。通过app查看和表来查看。","categories":[{"name":"缺陷","slug":"缺陷","permalink":"http://aemonswift.github.io/categories/%E7%BC%BA%E9%99%B7/"},{"name":"工作错误","slug":"缺陷/工作错误","permalink":"http://aemonswift.github.io/categories/%E7%BC%BA%E9%99%B7/%E5%B7%A5%E4%BD%9C%E9%94%99%E8%AF%AF/"}],"tags":[{"name":"缺陷","slug":"缺陷","permalink":"http://aemonswift.github.io/tags/%E7%BC%BA%E9%99%B7/"}]},{"title":"常见限流算法","slug":"常见限流算法","date":"2019-10-28T05:19:27.000Z","updated":"2019-10-28T11:37:41.703Z","comments":true,"path":"2019/10/28/常见限流算法/","link":"","permalink":"http://aemonswift.github.io/2019/10/28/%E5%B8%B8%E8%A7%81%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/","excerpt":"","text":"为什么需要限流算法在高并发系统中，保护系统三大利器：缓存，降级，限流，即主要降低数据库的访问。当请求量超过系统负载的时候，为了保证系统正常运行，当请求达到一定的并发数或速率，就需要进行等待、排队、降级、拒绝服务等，从而保证了有效系统正常运行。按照服务调用方分为如下几种类型 与用户打交道服务 这类服务导致系统负载过高原因： 用户增长过快（好事） 某个热点事件（微博热搜） 竞争对象爬虫 恶意刷单 这类系统都是无法预知的，即弹性扩容根本不可能实现。 对内的RPC服务一个服务A的接口可能被B，C，D，E多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对C，D，E也无法提供服务。解决方案如下：a.每个调用方采用线程池进行资源隔离；b.使用限流手段对每个调用方进行限流。 常见的限流算法计数器，令牌桶，漏桶，窗口等 计数器限流主要用来限制总并发数，比如数据库连接池大小、线程池大小、程序访问并发数等都是使用计数器算法。 计数器限流示例——通过限制系统的并发调用程度来限流例如go官方包里面httpServer频率限制，基本思路就是为连接数计数，通过make chan来建立一个最大连接数的channel, 每次accept就+1，close时候就-1. 当到达最大连接数时，就等待空闲连接出来之后再accept。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package netutil // import \"golang.org/x/net/netutil\" import ( \"net\" \"sync\") type limitListener struct &#123; net.Listener sem chan struct&#123;&#125; closeOnce sync.Once // ensures the done chan is only closed once done chan struct&#123;&#125; // no values sent; closed when Close is called&#125;type limitListenerConn struct &#123; net.Conn releaseOnce sync.Once release func()&#125; // LimitListener returns a Listener that accepts at most n simultaneous// connections from the provided Listener.func LimitListener(l net.Listener, n int) net.Listener &#123; return &amp;limitListener&#123; Listener: l, sem: make(chan struct&#123;&#125;, n), done: make(chan struct&#123;&#125;), &#125;&#125; // acquire acquires the limiting semaphore. Returns true if successfully// accquired, false if the listener is closed and the semaphore is not// acquired.func (l *limitListener) acquire() bool &#123; select &#123; case &lt;-l.done: return false case l.sem &lt;- struct&#123;&#125;&#123;&#125;: return true &#125;&#125;func (l *limitListener) release() &#123; &lt;-l.sem &#125; func (l *limitListener) Accept() (net.Conn, error) &#123; //如果sem满了，就会阻塞在这 acquired := l.acquire() // If the semaphore isn't acquired because the listener was closed, expect // that this call to accept won't block, but immediately return an error. c, err := l.Listener.Accept() if err != nil &#123; if acquired &#123; l.release() &#125; return nil, err &#125; return &amp;limitListenerConn&#123;Conn: c, release: l.release&#125;, nil&#125; func (l *limitListener) Close() error &#123; err := l.Listener.Close() l.closeOnce.Do(func() &#123; close(l.done) &#125;) return err&#125; func (l *limitListenerConn) Close() error &#123; err := l.Conn.Close() //close时释放占用的sem l.releaseOnce.Do(l.release) return err&#125;//单元测试package netutilimport ( \"errors\" \"fmt\" \"io\" \"io/ioutil\" \"net\" \"net/http\" \"sync\" \"sync/atomic\" \"testing\" \"time\" \"golang.org/x/net/internal/nettest\")func TestLimitListener(t *testing.T) &#123; const max = 5 attempts := (nettest.MaxOpenFiles() - max) / 2 if attempts &gt; 256 &#123; // maximum length of accept queue is 128 by default attempts = 256 &#125; l, err := net.Listen(\"tcp\", \"127.0.0.1:0\") if err != nil &#123; t.Fatal(err) &#125; defer l.Close() l = LimitListener(l, max) var open int32 go http.Serve(l, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if n := atomic.AddInt32(&amp;open, 1); n &gt; max &#123; t.Errorf(\"%d open connections, want &lt;= %d\", n, max) &#125; defer atomic.AddInt32(&amp;open, -1) time.Sleep(10 * time.Millisecond) fmt.Fprint(w, \"some body\") &#125;)) var wg sync.WaitGroup var failed int32 for i := 0; i &lt; attempts; i++ &#123; wg.Add(1) go func() &#123; defer wg.Done() c := http.Client&#123;Timeout: 3 * time.Second&#125; r, err := c.Get(\"http://\" + l.Addr().String()) if err != nil &#123; t.Log(err) atomic.AddInt32(&amp;failed, 1) return &#125; defer r.Body.Close() io.Copy(ioutil.Discard, r.Body) &#125;() &#125; wg.Wait() // We expect some Gets to fail as the kernel's accept queue is filled, // but most should succeed. if int(failed) &gt;= attempts/2 &#123; t.Errorf(\"%d requests failed within %d attempts\", failed, attempts) &#125;&#125; 使用count进行统计当前正在并发执行的次数，如果超过域值就简单粗暴的直接响应给用户，说明系统繁忙，请稍后再试或其它跟业务相关的信息。$\\color{red}{弊端：}$使用count简单粗暴超过域值就拒绝请求，可能只是瞬时的请求量高，也会拒绝请求。 计数器限流示例2——通过限制单位时间段内调用量来限流上述方法简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。 12345678910111213141516171819202122232425262728293031323334type AbandonReqLimitService struct &#123; Interval time.Duration // 设置计数器的时间间隔 MaxCount int // 计数器的最大值 Lock sync.Mutex // 锁 ReqCount int // 计数器&#125;func CreateAbandonReqLimitService(interval time.Duration, maxCount int) *AbandonReqLimitService &#123; reqLimit := &amp;AbandonReqLimitService&#123; Interval: interval, MaxCount: maxCount, &#125; go func() &#123; // 开启一个go协程来定时更新计数器 ticker := time.NewTicker(interval) // go中的定时器 for &#123; &lt;-ticker.C reqLimit.Lock.Lock() reqLimit.ReqCount = 0 reqLimit.Lock.Unlock() &#125; &#125;() return reqLimit&#125;func (reqLimit *AbandonReqLimitService) GetTokenAbandonRequest() bool &#123; // 取令牌函数 reqLimit.Lock.Lock() defer reqLimit.Lock.Unlock() if reqLimit.ReqCount &lt; reqLimit.MaxCount &#123; reqLimit.ReqCount += 1 return true &#125; else &#123; return false &#125;&#125; $\\color{red}{弊端：}$如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能请求拒绝，我们把这种现象称为“突刺现象”. 计数器限流示例3——采用队列的形式形式类似信号量Semaphore。 123456789101112131415type SemaphoreService struct &#123; Semaphore chan struct&#123;&#125;&#125;func CreateSemaphore(maxCnt int) chan struct&#123;&#125;&#123; return make(chan struct&#123;&#125;,maxCnt)&#125;func(semaphore *SemaphoreService)Accquire()&#123; semaphore.Semaphore&lt;-struct&#123;&#125;&#123;&#125;&#125;func (semaphore *SemaphoreService) Release()&#123; &lt;-semaphore.Semaphore&#125; 如果是瞬时的高并发，可以使请求在阻塞队列中排队，而不是马上拒绝请求，从而达到一个流量削峰的目的。$\\color{red}{但无法应对短时间的突发流量。} 漏桶限流为了消除”突刺现象”，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package ratelimiterimport ( \"sync\" \"time\")type rateLimiter struct &#123; lck *sync.Mutex rate float64 //最大速率限制 balance float64 //漏桶的余量 limit float64 //漏桶的最大容量限制 lastTime time.Time //上次检查的时间&#125;func NewRateLimiter(limitPerSecond int, balance int) *rateLimiter &#123; return &amp;rateLimiter&#123; lck: new(sync.Mutex), rate: float64(limitPerSecond), balance: float64(balance), limit: float64(balance), lastTime: time.Now(), &#125;&#125;func (r *rateLimiter) Check() bool &#123; ok := false r.lck.Lock() now := time.Now() dur := now.Sub(r.lastTime).Seconds() r.lastTime = now water := dur * r.rate //计算这段时间内漏桶流出水的流量water r.balance += water //漏桶流出water容量的水，自然漏桶的余量多出water if r.balance &gt; r.limit &#123; r.balance = r.limit &#125; if r.balance &gt;= 1 &#123; //漏桶余量足够容下当前的请求 r.balance -= 1 ok = true &#125; r.lck.Unlock() return ok&#125;//单元测试package ratelimiterimport ( \"fmt\" \"testing\" \"time\")func TestRateLimiter_Check(t *testing.T) &#123; limiter := NewRateLimiter(10, 1) start := time.Now() count := 0 for i := 0; i &lt; 1e3; i++ &#123; if limiter.Check() &#123; fmt.Println(i) count++ &#125; time.Sleep(time.Millisecond) &#125; fmt.Println(\"count:\", count) fmt.Println(time.Now().Sub(start).Seconds())&#125; 漏桶算法能够强行限制数据的传输速率，$\\color{blue}{但无法应对短时间的突发流量}$。 令牌桶限流从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。令牌桶算法（Token Bucket）：是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。一个简单的实现：利用的就是channel的阻塞操作。我们把一个指定尺寸channel，相当于一个指定容量的令牌桶，每一个空闲位置就是一个令牌。由于channel满时就无法向其中加元素，所以我们就可以以固定的速率消费channel中的消息（释放空间相当于添加令牌），取令牌就是添加一条消息，当令牌桶满时就无法正常添加消息（取令牌）了，这样就利用channel来构造了一个限流器。 1234567891011121314151617181920type NotAbandonReqLimitService struct &#123; TokenPool chan bool // 令牌桶&#125;func CreateNewRequestLimitService(interval time.Duration, maxCnt int) *NotAbandonReqLimitService &#123; reqLimit := &amp;NotAbandonReqLimitService&#123;&#125; reqLimit.TokenPool = make(chan bool, maxCnt) // 令牌桶最大容量 go func() &#123; tmpStr := strconv.Itoa(maxCnt) maxCntInt64,_ := strconv.ParseInt(tmpStr, 10, 64) ticker := time.NewTicker( time.Duration(interval.Nanoseconds()/(maxCntInt64*1000*1000))* time.Millisecond) // 匀速添加令牌，1s/最大qps 就是添加的速率 for &#123; &lt;- ticker.C &lt;- reqLimit.TokenPool &#125; &#125;() return reqLimit&#125;func (reqLimit *NotAbandonReqLimitService) GetTokenNotAbandonRequest() &#123; reqLimit.TokenPool &lt;- true // 消费令牌&#125; 例如go官方包rate，其思想为：用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中），桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349package rate import ( \"fmt\" \"math\" \"sync\" \"time\" \"golang.org/x/net/context\") // Limit defines the maximum frequency of some events.// Limit is represented as number of events per second.// A zero Limit allows no events.type Limit float64 // Inf is the infinite rate limit; it allows all events (even if burst is zero).const Inf = Limit(math.MaxFloat64) // Every converts a minimum time interval between events to a Limit.func Every(interval time.Duration) Limit &#123; if interval &lt;= 0 &#123; return Inf &#125; return 1 / Limit(interval.Seconds())&#125; // A Limiter controls how frequently events are allowed to happen.// It implements a \"token bucket\" of size b, initially full and refilled// at rate r tokens per second.// Informally, in any large enough time interval, the Limiter limits the// rate to r tokens per second, with a maximum burst size of b events.// As a special case, if r == Inf (the infinite rate), b is ignored.// See https://en.wikipedia.org/wiki/Token_bucket for more about token buckets.//// The zero value is a valid Limiter, but it will reject all events.// Use NewLimiter to create non-zero Limiters.//// Limiter has three main methods, Allow, Reserve, and Wait.// Most callers should use Wait.//// Each of the three methods consumes a single token.// They differ in their behavior when no token is available.// If no token is available, Allow returns false.// If no token is available, Reserve returns a reservation for a future token// and the amount of time the caller must wait before using it.// If no token is available, Wait blocks until one can be obtained// or its associated context.Context is canceled.//// The methods AllowN, ReserveN, and WaitN consume n tokens.type Limiter struct &#123; //maximum token, token num per second limit Limit //burst field, max token num burst int mu sync.Mutex //tokens num, change tokens float64 // last is the last time the limiter's tokens field was updated last time.Time // lastEvent is the latest time of a rate-limited event (past or future) lastEvent time.Time&#125; // Limit returns the maximum overall event rate.func (lim *Limiter) Limit() Limit &#123; lim.mu.Lock() defer lim.mu.Unlock() return lim.limit&#125; // Burst returns the maximum burst size. Burst is the maximum number of tokens// that can be consumed in a single call to Allow, Reserve, or Wait, so higher// Burst values allow more events to happen at once.// A zero Burst allows no events, unless limit == Inf.func (lim *Limiter) Burst() int &#123; return lim.burst&#125; // NewLimiter returns a new Limiter that allows events up to rate r and permits// bursts of at most b tokens.func NewLimiter(r Limit, b int) *Limiter &#123; return &amp;Limiter&#123; limit: r, burst: b, &#125;&#125; // Allow is shorthand for AllowN(time.Now(), 1).func (lim *Limiter) Allow() bool &#123; return lim.AllowN(time.Now(), 1)&#125; // AllowN reports whether n events may happen at time now.// Use this method if you intend to drop / skip events that exceed the rate limit.// Otherwise use Reserve or Wait.func (lim *Limiter) AllowN(now time.Time, n int) bool &#123; return lim.reserveN(now, n, 0).ok&#125; // A Reservation holds information about events that are permitted by a Limiter to happen after a delay.// A Reservation may be canceled, which may enable the Limiter to permit additional events.type Reservation struct &#123; ok bool lim *Limiter tokens int //This is the time to action timeToAct time.Time // This is the Limit at reservation time, it can change later. limit Limit&#125; // OK returns whether the limiter can provide the requested number of tokens// within the maximum wait time. If OK is false, Delay returns InfDuration, and// Cancel does nothing.func (r *Reservation) OK() bool &#123; return r.ok&#125; // Delay is shorthand for DelayFrom(time.Now()).func (r *Reservation) Delay() time.Duration &#123; return r.DelayFrom(time.Now())&#125; // InfDuration is the duration returned by Delay when a Reservation is not OK.const InfDuration = time.Duration(1&lt;&lt;63 - 1) // DelayFrom returns the duration for which the reservation holder must wait// before taking the reserved action. Zero duration means act immediately.// InfDuration means the limiter cannot grant the tokens requested in this// Reservation within the maximum wait time.func (r *Reservation) DelayFrom(now time.Time) time.Duration &#123; if !r.ok &#123; return InfDuration &#125; delay := r.timeToAct.Sub(now) if delay &lt; 0 &#123; return 0 &#125; return delay&#125; // Cancel is shorthand for CancelAt(time.Now()).func (r *Reservation) Cancel() &#123; r.CancelAt(time.Now()) return&#125; // CancelAt indicates that the reservation holder will not perform the reserved action// and reverses the effects of this Reservation on the rate limit as much as possible,// considering that other reservations may have already been made.func (r *Reservation) CancelAt(now time.Time) &#123; if !r.ok &#123; return &#125; r.lim.mu.Lock() defer r.lim.mu.Unlock() if r.lim.limit == Inf || r.tokens == 0 || r.timeToAct.Before(now) &#123; return &#125; // calculate tokens to restore // The duration between lim.lastEvent and r.timeToAct tells us how many tokens were reserved // after r was obtained. These tokens should not be restored. restoreTokens := float64(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct)) if restoreTokens &lt;= 0 &#123; return &#125; // advance time to now now, _, tokens := r.lim.advance(now) // calculate new number of tokens tokens += restoreTokens if burst := float64(r.lim.burst); tokens &gt; burst &#123; tokens = burst &#125; // update state r.lim.last = now r.lim.tokens = tokens if r.timeToAct == r.lim.lastEvent &#123; prevEvent := r.timeToAct.Add(r.limit.durationFromTokens(float64(-r.tokens))) if !prevEvent.Before(now) &#123; r.lim.lastEvent = prevEvent &#125; &#125; return&#125; // Reserve is shorthand for ReserveN(time.Now(), 1).func (lim *Limiter) Reserve() *Reservation &#123; return lim.ReserveN(time.Now(), 1)&#125; // ReserveN returns a Reservation that indicates how long the caller must wait before n events happen.// The Limiter takes this Reservation into account when allowing future events.// ReserveN returns false if n exceeds the Limiter's burst size.// Usage example:// r, ok := lim.ReserveN(time.Now(), 1)// if !ok &#123;// // Not allowed to act! Did you remember to set lim.burst to be &gt; 0 ?// &#125;// time.Sleep(r.Delay())// Act()// Use this method if you wish to wait and slow down in accordance with the rate limit without dropping events.// If you need to respect a deadline or cancel the delay, use Wait instead.// To drop or skip events exceeding rate limit, use Allow instead.func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation &#123; r := lim.reserveN(now, n, InfDuration) return &amp;r&#125; // Wait is shorthand for WaitN(ctx, 1).func (lim *Limiter) Wait(ctx context.Context) (err error) &#123; return lim.WaitN(ctx, 1)&#125; // WaitN blocks until lim permits n events to happen.// It returns an error if n exceeds the Limiter's burst size, the Context is// canceled, or the expected wait time exceeds the Context's Deadline.func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) &#123; if n &gt; lim.burst &#123; return fmt.Errorf(\"rate: Wait(n=%d) exceeds limiter's burst %d\", n, lim.burst) &#125; // Check if ctx is already cancelled select &#123; case &lt;-ctx.Done(): return ctx.Err() default: &#125; // Determine wait limit now := time.Now() waitLimit := InfDuration if deadline, ok := ctx.Deadline(); ok &#123; waitLimit = deadline.Sub(now) &#125; // Reserve r := lim.reserveN(now, n, waitLimit) if !r.ok &#123; return fmt.Errorf(\"rate: Wait(n=%d) would exceed context deadline\", n) &#125; // Wait t := time.NewTimer(r.DelayFrom(now)) defer t.Stop() select &#123; case &lt;-t.C: // We can proceed. return nil case &lt;-ctx.Done(): // Context was canceled before we could proceed. Cancel the // reservation, which may permit other events to proceed sooner. r.Cancel() return ctx.Err() &#125;&#125; // SetLimit is shorthand for SetLimitAt(time.Now(), newLimit).func (lim *Limiter) SetLimit(newLimit Limit) &#123; lim.SetLimitAt(time.Now(), newLimit)&#125; // SetLimitAt sets a new Limit for the limiter. The new Limit, and Burst, may be violated// or underutilized by those which reserved (using Reserve or Wait) but did not yet act// before SetLimitAt was called.func (lim *Limiter) SetLimitAt(now time.Time, newLimit Limit) &#123; lim.mu.Lock() defer lim.mu.Unlock() now, _, tokens := lim.advance(now) lim.last = now lim.tokens = tokens lim.limit = newLimit&#125; // reserveN is a helper method for AllowN, ReserveN, and WaitN.// maxFutureReserve specifies the maximum reservation wait duration allowed.// reserveN returns Reservation, not *Reservation, to avoid allocation in AllowN and WaitN.func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation &#123; lim.mu.Lock() defer lim.mu.Unlock() if lim.limit == Inf &#123; return Reservation&#123; ok: true, lim: lim, tokens: n, timeToAct: now, &#125; &#125; now, last, tokens := lim.advance(now) // Calculate the remaining number of tokens resulting from the request. tokens -= float64(n) // Calculate the wait duration var waitDuration time.Duration if tokens &lt; 0 &#123; waitDuration = lim.limit.durationFromTokens(-tokens) &#125; // Decide result ok := n &lt;= lim.burst &amp;&amp; waitDuration &lt;= maxFutureReserve // Prepare reservation r := Reservation&#123; ok: ok, lim: lim, limit: lim.limit, &#125; if ok &#123; r.tokens = n r.timeToAct = now.Add(waitDuration) &#125; // Update state if ok &#123; lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct &#125; else &#123; lim.last = last &#125; return r&#125; // advance calculates and returns an updated state for lim resulting from the passage of time.// lim is not changed.func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) &#123; last := lim.last if now.Before(last) &#123; last = now &#125; // Avoid making delta overflow below when last is very old. maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed &gt; maxElapsed &#123; elapsed = maxElapsed &#125; // Calculate the new number of tokens, due to time that passed. delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens &gt; burst &#123; tokens = burst &#125; return now, last, tokens&#125; // durationFromTokens is a unit conversion function from the number of tokens to the duration// of time it takes to accumulate them at a rate of limit tokens per second.func (limit Limit) durationFromTokens(tokens float64) time.Duration &#123; seconds := tokens / float64(limit) return time.Nanosecond * time.Duration(1e9*seconds)&#125; // tokensFromDuration is a unit conversion function from a time duration to the number of tokens// which could be accumulated during that duration at a rate of limit tokens per second.func (limit Limit) tokensFromDuration(d time.Duration) float64 &#123; return d.Seconds() * float64(limit)&#125; 虽然在某些情况下使用单个全局速率限制器非常有用，但另一种常见情况是基于IP地址或API密钥等标识符为每个用户实施速率限制器。我们将使用IP地址作为标识符。简单实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( \"net/http\" \"sync\" \"time\" \"golang.org/x/time/rate\")// Create a custom visitor struct which holds the rate limiter for each// visitor and the last time that the visitor was seen.type visitor struct &#123; limiter *rate.Limiter lastSeen time.Time&#125;// Change the the map to hold values of the type visitor.var visitors = make(map[string]*visitor)var mtx sync.Mutex// Run a background goroutine to remove old entries from the visitors map.func init() &#123; go cleanupVisitors()&#125;func addVisitor(ip string) *rate.Limiter &#123; limiter := rate.NewLimiter(2, 5) mtx.Lock() // Include the current time when creating a new visitor. visitors[ip] = &amp;visitor&#123;limiter, time.Now()&#125; mtx.Unlock() return limiter&#125;func getVisitor(ip string) *rate.Limiter &#123; mtx.Lock() v, exists := visitors[ip] if !exists &#123; mtx.Unlock() return addVisitor(ip) &#125; // Update the last seen time for the visitor. v.lastSeen = time.Now() mtx.Unlock() return v.limiter&#125;// Every minute check the map for visitors that haven't been seen for// more than 3 minutes and delete the entries.func cleanupVisitors() &#123; for &#123; time.Sleep(time.Minute) mtx.Lock() for ip, v := range visitors &#123; if time.Now().Sub(v.lastSeen) &gt; 3*time.Minute &#123; delete(visitors, ip) &#125; &#125; mtx.Unlock() &#125;&#125;func limit(next http.Handler) http.Handler &#123; return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; limiter := getVisitor(r.RemoteAddr) if limiter.Allow() == false &#123; http.Error(w, http.StatusText(429), http.StatusTooManyRequests) return &#125; next.ServeHTTP(w, r) &#125;)&#125; 窗口限流Fixed Window固定窗口算法，设置一个时间段内（窗口）接收的请求数，超过的这个请求数的请求会被丢弃。 窗口通常选择人们熟悉的时间段：1 分钟／1小时 窗口的起始时间通常是当前时间取地板（floor），比如 12:00:03 所在的窗口 （以一分钟的窗口为例）就是 12:00:00 - 12:01:00和漏桶相比，能够让新来的请求也能够被处理到，但存在缺点： 在窗口的起始时间，最差情况下可能会带来 2 倍的流量 很多消费者可能都在等待窗口被重置，造成惊群效应（惊群效应：当某一资源可用时，n个进程/线程会惊醒，竞争资源。导致n-1个进程/线程做了无效的调度,上下文切换，cpu瞬时增高） Sliding Log滑动日志算法，利用记录下来的用户的请求时间，请求数，当该用户的一个新的 请求进来时，比较这个用户在这个窗口内的请求数是否超过了限定值，超过的话 就拒绝这个请求。优点： 避免了固定窗口算法在窗口边界可能出现的两倍流量问题 由于是针对每个用户进行统计的，不会引发惊群效应缺点： 需要保存大量的请求日志 每个请求都需要考虑该用户之前的请求情况，在分布式系统中尤其难做到 Sliding Window滑动窗口算法，结合了固定窗口算法的低开销和滑动日志算法能够解决的边界情况。 为每个窗口进行请求量的计数 结合上一个窗口的请求量和这一个窗口已经经过的时间来计算出上限，以此 平滑请求尖锋举例来说，限流的上限是每分钟 10 个请求，窗口大小为 1 分钟，上一个 窗口中总共处理了 6 个请求。现在假设这个新的窗口已经经过了 20 秒，那么 到目前为止允许的请求上限就是 10 - 6 * (1 - 20 / 60) = 8。滑动窗口算法是这些算法中最实用的算法： 避免了漏桶算法带来的饥饿问题 避免了固定窗口算法的请求量突增的问题 集群限流上述限流方法都是单机限流的范畴，比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。难点在于限流上限都是针对全站的流量设置的，那么每个节点该如何协调各自处理的量呢？ 同步的策略解决的方法通常都是使用一个统一的数据库来存放计数，比如 Redis 或者 Cassandra。 数据库中将存放每个窗口和用户的计数值。这种方法的主要问题是需要多访问一次数据库， 以及竞争问题。 竞争问题竞争问题就是当有两个以上的线程同时执行 i += 1 的时候，如果没有同步这 些操作的话，i 的值可能会有多种情况。处理竞争问题可以通过加锁来做，不过在限流的场景下，这样做肯定会成为系统的瓶颈， 毕竟限流时每个请求都会来竞争这个锁。更好的办法是通过 set-then-get 的方法，限流场景中用到的只是计数 +1， 利用这一点以及数据库实现的性能更好的原子操作可以达到我们的目的。 性能优化利用集中式的数据库的另一个问题是每次请求都要查一下数据库带来的延迟开销， 数据库再快也会带来几毫秒的延迟。解决这个问题的方法可以通过在内存里面维护一个计数值，代价是稍微的放松限 流的精确度。通过设置一个定时任务从数据库拿计数值，周期内在内存中维护这 个计数，周期结束时把计数同步到数据库并拿取新的计数，如此往复。这个同步周期往往是做成可以配置的，小的周期能够带来更精确的限流， 大的周期则能减轻数据库的 I/O 压力。 参考文献基于令牌桶算法和漏桶算法来实现的限速限流轻量级限流中间件漏桶算法&amp;令牌桶算法理解及常用的算法go channel实现简单信号量go语言生产者消费者信号量实现Golang实现请求限流的几种办法高并发系统限流-漏桶算法和令牌桶算法谈谈服务限流算法的几种实现常用的限流算法高并发系统限流中的漏桶算法和令牌桶算法，通过流量整形和速率限制提升稳定性高并发系统限流中的算法限流算法比较与实现接口限流算法（关于临界点处理）限流算法的理解和应用场景和实现高并发中的惊群效应","categories":[{"name":"系统","slug":"系统","permalink":"http://aemonswift.github.io/categories/%E7%B3%BB%E7%BB%9F/"},{"name":"限流","slug":"系统/限流","permalink":"http://aemonswift.github.io/categories/%E7%B3%BB%E7%BB%9F/%E9%99%90%E6%B5%81/"}],"tags":[{"name":"系统","slug":"系统","permalink":"http://aemonswift.github.io/tags/%E7%B3%BB%E7%BB%9F/"},{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"路径规划——Floyd","slug":"路径规划——Floyd","date":"2019-10-25T01:22:00.000Z","updated":"2019-10-25T02:28:56.736Z","comments":true,"path":"2019/10/25/路径规划——Floyd/","link":"","permalink":"http://aemonswift.github.io/2019/10/25/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92%E2%80%94%E2%80%94Floyd/","excerpt":"","text":"思想$\\color{red}{主要用来求解：}$任意两点的最短路径。该算法采用了动态规划的思想。$\\color{red}{思想如下：}$A到B，可以经历中转站得来降低成本；当考虑了所有的中转站的时候，则可以得到此图在A到B的最低成本。\b$\\color{red}{适用范围：}$解决多源路径问题。 算法步骤 初始化边矩阵M； 从U中选取顶点k加入S中，并将此元素从U中移除； 以k为中转站，更新边矩阵M的信息； 重复步骤2和3，直到所有顶点都包含在S中。例子 a. 初始化M矩阵,即经过A点的M矩阵 * A B C D E F A 0 6 3 $\\infty$ $\\infty$ $\\infty$ B 6 0 2 5 $\\infty$ $\\infty$ C 3 2 0 3 4 $\\infty$ D $\\infty$ 5 3 0 2 3 E $\\infty$ $\\infty$ 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 b. 考虑经过B点，更新M矩阵 * A B C D E F A 0 6 3 11 $\\infty$ $\\infty$ B 6 0 2 5 $\\infty$ $\\infty$ C 3 2 0 3 4 $\\infty$ D 11 5 3 0 2 3 E $\\infty$ $\\infty$ 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 c. 考虑经过C点，更新M矩阵 * A B C D E F A 0 5 3 6 7 $\\infty$ B 5 0 2 5 6 $\\infty$ C 3 2 0 3 4 $\\infty$ D 6 5 3 0 2 3 E 7 6 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 d. 考虑经过D点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 e. 考虑经过E点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 f. 考虑经过F点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 算法实现头文件描述123456789101112131415161718192021222324pragma once#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;stringstream&gt;using namespace std;class GraphDG&#123;private: int pointSum; int edge; int **adjacentMat； int **dis; int **path; string intToString(int target) bool checkEdgeValue(int start,int end,int weight);public: GraphDG(int pointSum,int edge); ~GraphDG(); void createGraph(int); void print(); void Floyd(); void printMinPath();&#125;; 功能实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# include \"Floyd.h\"const INT_MAX=2^32-1;GraphDG::GraphDG(int pointSum,int edge)&#123; this-&gt;pointSum=pointSum; this-&gt;edge=edge; this-&gt;adjacentMat=new int*[this-&gt;pointSum]; this-&gt;dis=new int*[this-&gt;pointSum]; this-&gt;path=new int*[this-&gt;pointSum]; for(int i=0;i&lt;this-&gt;pointSum;i++)&#123; adjacentMat[i]=new int[this-&gt;pointSum]; dis[i]=new int[this-&gt;pointSum]; path[i]=new int[this-&gt;pointSum]; for (int j=0;j&lt;this-&gt;pointSum;j++)&#123; adjacentMat[i][j]=INT_MAX; &#125; &#125;&#125;GraphDG::~GraphDG()&#123; for (int i=0;i&lt;this-&gt;pointSum;i++)&#123; delete adjacentMat[i]; delete dis[i]; delete path[i]; &#125; delete adjacentMat; delete dis; delete path;&#125;bool GraphDG::checkEdgeValue(int start,int end,int weight)&#123; if (start&lt;1||end&lt;1||start&gt;end||end&gt;pointSum||weight&lt;0)&#123; return false; &#125; return true;&#125;void GraphDG::createGraph(int kind)&#123; cout &lt;&lt; \"请输入每条边的起点和终点（顶点编号从1开始）以及其权重\" &lt;&lt; endl; int start,end,weight; for (int i=0;i&lt;this-&gt;edge;i++&gt;)&#123; cin&gt;&gt;start&gt;&gt;end&gt;&gt;weight; while(!this-&gt;checkEdgeValue(start,end,weight))&#123; cout &lt;&lt; \"输入的边的信息不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; start &gt;&gt; end &gt;&gt; weight; &#125; adjacentMat[start-1][end-1]=weight; //变成无向图 if (kind==2)&#123; adjacentMat[end-1][start-1]=weight; &#125; &#125;&#125;void GraphDG::print()&#123; cout &lt;&lt; \"图的邻接矩阵为：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointSum;row++&gt;)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; if adjacentMat[row][col]==INT_MAX&#123; cout&lt;&lt;\"i \"; &#125;else&#123; cout&lt;&lt;adjacentMat[row][col]&lt;&lt;\" \"; &#125; &#125; cout&lt;&lt;endl; &#125; cout &lt;&lt;endl;&#125;//思想在于：A到B，可以经历中转站得来降低成本；当考虑了所有的中转站的时候，则可以得到此图在A到B的最低成本。——动态规划思想void GraphDG::Floyd()&#123; for (int row=0;row&lt;this-&gt;pointSum;row++)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; this-&gt;dis[row][col]=this-&gt;adjacentMat[row][col]; this-&gt;path[row][col]=col; &#125; &#125; for (int temp =0;temp&lt;this-&gt;pointSum;temp++)&#123; //temp为中转站 for (int i=0;i&lt;this-&gt;pointSum;i++)&#123; for(int j=0;j&lt;this-&gt;pointSum;j++)&#123; select=(dis[row][temp] == INT_MAX || dis[temp][col] == INT_MAX) ? INT_MAX : (dis[row][temp] + dis[temp][col]); if(this-&gt;dis[i][j]&gt;select)&#123; this-&gt;dis[i][j]=select; this-&gt;path[i][j]=this-&gt;path[i][temp]; &#125; &#125; &#125; &#125;&#125;void GraphDG::printMinPath()&#123; cout &lt;&lt; \"各个顶点对的最短路径：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointSum;row++)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; cout&lt;&lt;\"v\"&lt;&lt;intToString(row+1)&lt;&lt;\"--\"&lt;&lt;\"v\"&lt;&lt;intToString(col+1)&lt;&lt;\"weight:\" &lt;&lt;this-&gt;dis[row][col]&lt;&lt;\"path:\"&lt;&lt;\"v\"&lt;&lt;intToString(row+1); temp=path[row][col]; while(temp!=col)&#123; cout&lt;&lt;\"--&gt;\"&lt;&lt;\"v\"&lt;&lt;intToString(temp+1); temp=path[temp][col]; &#125; cout&lt;&lt;\"--&gt;\"&lt;&lt;\"v\"&lt;&lt;intToString(col+1)&lt;&lt;endl; &#125; cout&lt;&lt;endl; &#125;&#125;string GraphDG::intToString(int target)&#123; stringstream ss; ss&lt;&lt;target; return ss&gt;&gt;; &#125; 测试函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include \"Floyd.h\"bool check(int pointSum,int edge)&#123; if (pointSum&lt;=1||edge&lt;=0||(pointSum-1)*pointSum&lt;edge)&#123; return false; &#125; return true;&#125;int main()&#123; int pointSum,edge,kind; cout &lt;&lt; \"输入图的种类：1代表有向图，2代表无向图\" &lt;&lt; endl; cin&gt;&gt;kind; while(true)&#123; if (kind==1||kind==2)&#123; break; &#125;else&#123; cout &lt;&lt; \"输入的图的种类编号不合法，请重新输入：1代表有向图，2代表无向图\" &lt;&lt; endl; cin &gt;&gt; kind; &#125; &#125; cout &lt;&lt; \"输入图的顶点个数和边的条数：\" &lt;&lt; endl; cin &gt;&gt; pointSum &gt;&gt; edge; while (!check(pointSum, edge)) &#123; cout &lt;&lt; \"输入的数值不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; pointSum &gt;&gt; edge; &#125; GraphDG graph(pointSum,edge); graph.createGraph(kind); graph.print(); graph.Floy(); graph.printMinPath(); system(\"pause\"); return 0&#125;//输入参数// 2// 7 12// 1 2 12// 1 6 16// 1 7 14// 2 3 10// 2 6 7// 3 4 3// 3 5 5// 3 6 6// 4 5 4// 5 6 2// 5 7 8// 6 7 9 算法缺陷可以求有负权值的边，但是不能有负回路。","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"算法/路径规划","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"路径规划","permalink":"http://aemonswift.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]},{"title":"路径规划——Dijkstra","slug":"路径规划——Dijkstra","date":"2019-10-24T07:03:06.000Z","updated":"2019-10-25T01:45:09.631Z","comments":true,"path":"2019/10/24/路径规划——Dijkstra/","link":"","permalink":"http://aemonswift.github.io/2019/10/24/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92%E2%80%94%E2%80%94Dijkstra/","excerpt":"","text":"思想$\\color{red}{主要用来求解：}$从起始点到其他所有点的最短路径。该算法采用了贪心的思想。$\\color{red}{思想如下：}$A到B可以有多个中转站集合U，如何选择中转站？本算法选择最低的成本的中转站，即将C1加入到需要走的中转站集合S中，在目前集合S情况下，得到了A到所有各站的成本，在此成本基础上选择最低的成本加入到需要走的中转站集合S中，重复上述操作。\b$\\color{red}{适用范围：}$解决单源路径问题。 算法步骤 初始化时，S只含有源节点； 从U中选取一个距离v最小的顶点k加入S中（该选定的距离就是v到k的最短路径长度），并将此元素从U中移除； 以k为新考虑的中间点，修改U中各顶点的距离；若从源节点v到顶点u的距离（经过顶点k）比原来距离（不经过顶点k）短，则修改顶点u的距离值，修改后的距离值是顶点k的距离加上k到u的距离； 重复步骤2和3，直到所有顶点都包含在S中。例子从A开始出发，到其他所有点的最短距离和路径 步骤 描述 1 初始化距离$dis=[0,6,3,\\infty,\\infty,\\infty,\\infty]$，此时S={A},U={B,C,D,E,F} 2 排除S中的点，寻找dis中最小距离的点C,此时距离为$dis=[0,5,3,6,7,\\infty]$，此时S={A,C},U={B,D,E,F} 3 排除S中的点，寻找dis中最小距离的点B，此时距离变为$dis=[0,5,3,6,7,\\infty]$，此时S={A,C,B},U={D,E,F} 4 排除S中的点，寻找dis中最小距离的点D，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D},U={E,F} 5 排除S中的点，寻找dis中最小距离的点E，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D,E},U={F} 6 排除S中的点，寻找dis中最小距离的点F，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D,F},U={} 算法实现头文件描述1234567891011121314151617181920212223242526272829303132333435363738// Dijkstra.h# pragma once //pragma once是一个比较常用的C/C++声明，只要在头文件的最开始加入这条杂注，就能够保证头文件只被编译一次。# include &lt;iostream&gt;# include &lt;string&gt;#include &lt;sstream&gt;using namespace std;struct Dis&#123; string path; int value; bool visit; int prePoint; //记录到当前节点的上一个节点是谁 Dis()&#123; visit=false; value=0; path=\"\"; minPath=nullptr; &#125;&#125;;class GraphDG&#123;private: int pointNum; int edge; int **adjacentMat； Dis*dis; string intToString(int target); bool checkEdgeValue(int start,int end,int weight);public: GraphDG(int pointNum,int edge); ~GraphDG(); void createGraph(); void print(); void resloveMinPath(int begin); void printSearchPath(int begin); void printMinPath(int begin,int end);&#125;; 功能实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# include \"Dijkstra.h\"const INT_MAX=2^31-1;GraphDG::GraphDG(int pointNum,int edge)&#123; this-&gt;pointNum=pointNum; this-&gt;edge=edge; adjacentMat=new int* [this-&gt;pointNum]; dis=new Dis[this-&gt;pointNum]; for(int i=0;i&lt;this-&gt;pointNum;i++)&#123; adjacentMat=new int[this-&gt;pointNum]; for int(j=0;j&lt;this-&gt;pointNum;j++)&#123; adjacentMat[i][j]=INT_MAX; //开始赋值无穷大 &#125; &#125;&#125;GraphDG::~GraphDG() &#123; delete dis; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; delete this-&gt;adjacentMat[i]; &#125; delete this-&gt;adjacentMat;&#125;bool GraphDG::checkEdgeValue(int start,int end,int weight)&#123; if (start&lt;1||end&lt;1||start&gt;this-&gt;pointNum||end&gt;this-&gt;pointNum||weight&lt;0)&#123; return false; &#125; return true;&#125;void GraphDG::createGraph()&#123; cout &lt;&lt; \"请输入每条边的起点和终点（顶点编号从1开始）以及其权重\" &lt;&lt; endl; int start,end,weight,count=0; while(count!=this-&gt;edge)&#123; cin&gt;&gt;start&gt;&gt;end&gt;&gt;weight; while(!this-&gt;checkEdgeValue(start,end,weight))&#123; cout &lt;&lt; \"输入的边的信息不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; start &gt;&gt; end &gt;&gt; weight; &#125; adjacentMat[start-1][end-1]=weight; // adjacentMat[end-1][start-1]=weight 加上这句为无向边 count++; &#125;&#125;void GraphDG::print(int begin)&#123; cout &lt;&lt; \"图的邻接矩阵为：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointNum;col++)&#123; for(int col=0;col&lt;this-&gt;pointNum;i++;col++)&#123; if (adjacentMat[row][col]==INT_MAX)&#123; cout&lt;&lt;\"infinity\"； &#125;else&#123; cout&lt;&lt;adjacentMat[row][col]; &#125; &#125; cout&lt;&lt;endl; &#125; cout&lt;&lt;endl;&#125;void GraphDG::printSearchPath(int begin)&#123; string str; str=\"v\"+intToString(begin); cout &lt;&lt; \"以\"&lt;&lt;str&lt;&lt;\"为起点的图的最短路径为：\" &lt;&lt; endl; for (int i=0;i!=this-&gt;pointNum;i++)&#123; if(dis[i].value!=INT_MAX)&#123; cout &lt;&lt; dis[i].path &lt;&lt; \"=\" &lt;&lt; dis[i].value &lt;&lt; endl; &#125;else&#123; cout &lt;&lt; dis[i].path &lt;&lt; \"是无最短路径的\" &lt;&lt; endl; &#125; &#125;&#125;void GraphDG::printMinpath(int begin,int end)&#123; string str; int prePoint=dis[end].prePoint; while(prePoint&gt;=0)&#123; proPoint=dis[prePoint].prePoint; if (prePoint==proPoint)&#123; break; &#125; str=intToString(prePoint+1)+\" \"+str; prePoint=proPoint; &#125; cout&lt;&lt;str;&#125;void GraphDG::Dijkstra(int begin)&#123; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; dis[i].path=\"v\"+intToString(begin)+\"--&gt;v\"+intToString(i+1); dis[i].value=adjacentMat[begin-1][i]; dis[i].prePoint=begin; &#125; dis[begin-1].value=0; dis[begin-1].visit=true; for (int count=1;count&lt;this-&gt;pointNum;count++)&#123; //找加入的最小值对应的下标 int temp=0,min=INT_MAX; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; if(!dis[i].visit&amp;&amp;dis[i].value&lt;INT_MAX)&#123; min=dis[i].value; temp=i &#125; &#125; dis[temp].visit=true; // 计算剩余点的最短路径 for (int i=0;i&lt;this-&gt;pointNum;i++&gt;)&#123; //注意这里的条件adjacentMat[temp][i]!=INT_MAX必须加，不然会出现溢出，从而造成程序异常 if(!dis[i].visit&amp;&amp;adjacentMat[temp][i]!=INT_MAX&amp;&amp;dis[temp].value+adjacentMat[temp][i]&lt;dis[i].value)&#123; dis[i].value=dis[temp].value+adjacentMat[temp][i]; dis[i].path=dis[temp].path+\"--&gt;v\"+intToString(i+1); dis[i].prePoint=temp; &#125; &#125; &#125;&#125;string GraphDG::intToString(int target)&#123; stringstream ss; ss&lt;&lt;target; return ss&gt;&gt;; &#125; 测试函数123456789101112131415161718192021222324252627282930313233343536#include \"Dijkstra.h\"bool check(int pointNum,int edge)&#123; if(pointNum&lt;=1||edge&lt;=0||(pointNum-1)*pointNum/2&lt;edge)&#123; return false; &#125; return true;&#125;int main()&#123; int pointNum,edge; cout &lt;&lt; \"输入图的顶点个数和边的条数：\" &lt;&lt; endl; cin &gt;&gt; pointNum &gt;&gt; edge; while (!check(vexnum, edge)) &#123; cout &lt;&lt; \"输入的数值不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; pointNum &gt;&gt; edge; &#125; GraphDG grpah(pointNum,edge); graph.createGraph(); graph.print(); graph.Dijkstra(); graph.printSearchPath(); graph.printMinPath(); system(\"pause\"); return 0;&#125;//输入参数// 6 8// 1 3 10// 1 5 30// 1 6 100// 2 3 5// 3 4 50// 4 6 10// 5 6 60// 5 4 20 算法缺陷若权重为负边的时候，此算法失效。","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"算法/路径规划","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"路径规划","permalink":"http://aemonswift.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]},{"title":"冒泡算法及其优化","slug":"冒泡算法及其优化","date":"2019-10-23T07:01:32.000Z","updated":"2019-10-24T02:03:06.983Z","comments":true,"path":"2019/10/23/冒泡算法及其优化/","link":"","permalink":"http://aemonswift.github.io/2019/10/23/%E5%86%92%E6%B3%A1%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/","excerpt":"","text":"思想给你一个数列，对相邻的两个个数进行比较，让大数下沉，或较小的数字进行上浮。 算法实现一般实现方法123456789101112void BubbleSort(int arr[],int len)&#123; int tmp=0; for (int i=0;i&lt;len;i++)&#123; for(int j=0;j&lt;len-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; &#125; &#125; &#125;&#125; 上述算法实现的缺陷：若排到一定时候，当数列再也没有发生交换（即顺序已经排好），但仍然进行循环。 优化1——\b引入有序标记针对一般实现方法，引入一个标记 flag，来判断是否发生来交换 1234567891011121314151617void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0; for (int i=0;i&lt;len;i++)&#123; flag=0; for(int j=0;j&lt;len-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; &#125; &#125; if (flag==0)&#123; return; &#125; &#125;&#125; 上述算法实现仍然有着缺陷：若排到一定时候，后面部分都有顺序，而只是前面部分没有顺序，会进行不必要的循环次数。 优化2——引入位置标记针对优化1实现的方法，引入一个位置标记pos，来记录从哪个位置开始时，后面的数据都有顺序。 1234567891011121314151617181920void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0,pos=0,k=len-1; for (int i=0;i&lt;len;i++)&#123; flag=0; pos=0; for(int j=0;j&lt;k;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; pos=j; &#125; &#125; if (flag==0)&#123; return; &#125; k=pos; &#125;&#125; 还没有方法来继续提高效率？ 优化3——鸡尾酒排序回归到冒泡思想：给你一个数列，对相邻的两个个数进行比较，让大数下沉，或较小的数字进行上浮。若一次排序让大数和小数一并都找到，这样大大缩小了第一层的循环次数。——称为鸡尾酒排序。pos标记从哪个位置开始时，后面的数据都有顺序。prepos标记从哪个位置开始时，前面的数据都有顺序。 12345678910111213141516171819202122232425262728293031323334void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0,pos=0,k=len-1,prepos=0; for (int i=0;i&lt;len;i++)&#123; flag=0; pos=0; for(int j=i;j&lt;k;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; pos=j; &#125; &#125; if (flag==0)&#123; return; &#125; k=pos; flag=0; for (int j=k;j&gt;i;j--)&#123; if (arr[j]&lt;arr[j-1])&#123; tmp=arr[j]; arr[j]=arr[j-1]; arr[j-1]=tmp; flag=1; prepos=j; &#125; &#125; if (flag==0)&#123; return; &#125; i=prepos-1; //由于i++操作，故需要进行减1操作，才能回到从哪个位置开始，前面都有序 &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"算法/排序","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"hello","slug":"hello","date":"2019-10-21T12:01:35.000Z","updated":"2019-10-22T00:59:53.081Z","comments":true,"path":"2019/10/21/hello/","link":"","permalink":"http://aemonswift.github.io/2019/10/21/hello/","excerpt":"","text":"问题描述问题为什么重要问题目前解决方案有哪些问题的难点是什么你的创新点是什么问题求解问题数学描述问世间，何许人也！","categories":[{"name":"音乐","slug":"音乐","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/"},{"name":"前端","slug":"音乐/前端","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/%E5%89%8D%E7%AB%AF/"},{"name":"后端","slug":"音乐/前端/后端","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/%E5%89%8D%E7%AB%AF/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"古典","slug":"古典","permalink":"http://aemonswift.github.io/tags/%E5%8F%A4%E5%85%B8/"},{"name":"轻音乐","slug":"轻音乐","permalink":"http://aemonswift.github.io/tags/%E8%BD%BB%E9%9F%B3%E4%B9%90/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-10-21T00:53:07.676Z","updated":"2019-10-21T00:53:07.676Z","comments":true,"path":"2019/10/21/hello-world/","link":"","permalink":"http://aemonswift.github.io/2019/10/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}