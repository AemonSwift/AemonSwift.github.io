{"meta":{"title":"长亭短亭","subtitle":"Man Propose, God Dispose.","description":null,"author":"AemonSwift","url":"http://aemonswift.github.io","root":"/"},"pages":[{"title":"categories","date":"2019-10-24T02:01:31.000Z","updated":"2019-10-24T02:08:24.653Z","comments":true,"path":"categories/index.html","permalink":"http://aemonswift.github.io/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2019-10-24T02:01:12.000Z","updated":"2019-10-24T02:08:13.934Z","comments":true,"path":"tags/index.html","permalink":"http://aemonswift.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"布隆过滤器","slug":"布隆过滤器","date":"2019-10-31T11:38:18.000Z","updated":"2019-10-31T11:45:54.393Z","comments":true,"path":"2019/10/31/布隆过滤器/","link":"","permalink":"http://aemonswift.github.io/2019/10/31/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"问题假设你现在要处理这样一个问题，你有一个网站并且拥有很多访客，每当有用户访问时，你想知道这个ip是不是第一次访问你的网站。这是一个很常见的场景，为了完成这个功能，你很容易就会想到下面这个解决方案：把访客的ip存进一个hash表中，每当有新的访客到来时，先检查哈希表中是否有改访客的ip，如果有则说明该访客在黑名单中。你还知道，hash表的存取时间复杂度都是O(1),效率很高，因此你对你的方案很是满意。然后我们假设你的网站已经被1亿个用户访问过，每个ip的长度是15，那么你一共需要$15 * 100000000 = 1500000000Bytes = 1.4G$，这还没考虑hash冲突的问题（hash表中的槽位越多，越浪费空间，槽位越少，效率越低）。于是聪明的你稍一思考，又想到可以把ip转换成无符号的int型值来存储，这样一个ip只需要占用4个字节就行了，这时1亿个ip占用的空间是$4 * 100000000 = 400000000Bytes = 380M$，空间消耗降低了很多。那还有没有在不影响存取效率的前提下更加节省空间的办法呢? BitSet32位无符号int型能表示的最大值是4294967295，所有的ip都在这个范围内，我们可以用一个bit位来表示某个ip是否出现过，如果出现过，就把代表该ip的bit位置为1，那么我们最多需要429496729个bit就可以表示所有的ip了。举个例子比如10.0.0.1转换成int是167772161，那么把长度为4294967295的bit数组的第167772161个位置置为1即可，当有ip访问时，只需要检查该标志位是否为1就行了。4294967295bit = 536870912Byte = 512M。如果用hash表示所有4294967295范围内的数组的话，需要十几G的空间。当然，这里举ip的例子不一定合适，主要目的是为了引出BitSet。 实现过程例子：首先，比如我们有一个长度=2的byte数组，2个字节一共有16位，可以表示0-15的数字是否存在。比如我们要验证11是否出现过，那么我们先检查第11个位置是否为1，如果为0，说明11没出现过，然后我们把第11位置为1，表示11已经出现过了。故BitSet基本只有两个操作，set(int value) 和 isHas(int value) set(int value)我们先来看set怎么实现，因为一个byte占8位，所以对于一个给定的value，我们先求出该value应该位于哪个Byte上，这很简单，int byteIndex = value / 8;找到value在byte数组中的位置后，再就是在该字节中寻找表示value的bit位，我们知道，一个byte其实就是一个长为8的bit数组，那么value在该bit数组中的位置也就很好算了，int bitIndex = value % 8;最后我们把该bit位设置为1就可以了：byte[byteIndex] = byte[byteIndex] | 1 &lt;&lt; ( 7 - bitIndex) 12345void set(int value)&#123; int byteIndex = value / 8; int bitIndex = value % 8; byte[byteIndex] = byte[byteIndex] | 1 &lt;&lt; (7 - bitIndex)&#125; isHas(int value)12345bool isHash(int value)&#123; int byteIndex = value / 8; int bitIndex = value % 8; return byte[byteIndex] &amp; 1 &lt;&lt; (7 - bitIndex) &gt; 0&#125; $\\color{red}{例子：}$比如我们有一个长度=2的byte数组，2个字节一共有16位，可以表示0-15的数字是否存在。比如我们要验证11是否出现过，那么我们先检查第11个位置是否为1，如果为0，说明11没出现过，然后我们把第11位置为1，表示11已经出现过了。 BitSet的局限性 当样本分布极度不均匀的时候，BitSet会造成很大空间上的浪费。比如你有10个数，分别是1、2、3、4、5、6、7、8、99999999999；那么你不得不用99999999999个bit位去实现你的BitSet,而这个BitSet的中间绝大多数位置都是0，并且永远不会用到，这显然是极度不划算的. 当元素不是整型的时候，BitSet就不适用了。若你拿到的是一堆url，然后如果你想用BitSet做去重的话，先得把url转换成int型，在转换的过程中难免某些url会计算出相同的int值，于是BitSet的准确性就会降低。那针对这两种情况有没有解决办法呢？第一种分布不均匀的情况可以通过hash函数，将元素都映射到一个区间范围内，减少大段区间闲置造成的浪费，这很简单，取模就好了，难的是取模之后的值保证不相同，即不发生hash冲突。第二种情况，把字符串映射成整数是必要的，那么唯一要做的就是保证我们的hash函数尽可能的减少hash冲突，一次不行我就多hash几次，hash还是容易碰撞，那我就扩大数组的范围，使hash值尽可能的均匀分布，减少hash冲突的概率。基于这种思想，BloomFilter诞生了。 布隆过滤器本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 “某样东西一定不存在或者可能存在”。相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是概率性的，而不是确切的。 核心思想 多个hash，增大随机性，减少hash碰撞的概率 扩大数组范围，使hash值均匀分布，进一步减少hash碰撞的概率。 底层数据结构布隆过滤器是一个 bit 向量或者说 bit 数组。例如：你有10个Url，你完全可以创建一长度是100bit的数组，然后对url分别用5个不同的hash函数进行hash，得到5个hash后的值，这5个值尽可能的保证均匀分布在100个bit的范围内。然后把5个hash值对应的bit位都置为1，判断一个url是否已经存在时，一次看5个bit位是否为1就可以了，如果有任何一个不为1，那么说明这个url不存在。$\\color{red}{这里需要注意的是，如果对应的bit位值都为1，那么也不能肯定这个url一定存在，这个是BloomFilter的特点之一。}$ BloomFilter的实践 黑名单。比如邮件黑名单过滤器，判断邮件地址是否在黑名单中 排序(仅限于BitSet)。仔细想想，其实BitSet在set(int value)的时候，“顺便”把value也给排序了。 网络爬虫。判断某个URL是否已经被爬取过 K-V系统快速判断某个key是否存在。典型的例子有Hbase，Hbase的每个Region中都包含一个BloomFilter，用于在查询时快速判断某个key在该region中是否存在，如果不存在，直接返回，节省掉后续的查询。 利用布隆过滤器减少磁盘 IO 或者网络请求，因为一旦一个值必定不存在的话，我们可以不用进行后续昂贵的查询请求。 既然你使用布隆过滤器来加速查找和判断是否存在，那么性能很低的哈希函数不是个好选择，推荐 MurmurHash、Fnv 这些。 大Value拆分Redis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。 BloomFilter的准确性——hash函数个数以及bit向量长度的选择问题从直观上看，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。 分析hash函数个数以隆过滤器长度的选择指导假设： k为hash函数个数 m为布隆过滤器长度 n插入元素的个数 p为误报率 $$m=-\\frac{nlnp}{(ln2)^2}$$$$k=\\frac{m}{n}ln2$$假设哈希函数以相等的概率选择每个数组位置。如果m是数组长度，则哈希函数未将某个位置置为1的概率为：$1-\\frac{1}{m}$。假设k是哈希函数的数量，并且每个散列函数之间没有显着相关性，则该位置未被任何哈希函数设置为1的概率为：$(1-\\frac{1}{m})^k$。如果我们插入了n个元素，此位置仍然为0的概率为：$(1-\\frac{1}{m})^{kn}$，故为1的概率为：$1-(1-\\frac{1}{m})^{kn}$。k个哈希函数都将此位置置为1的概率为：$p=(1-(1-\\frac{1}{m})^{kn})^k$。p也就是我们的误差率，我们需要最小化p值。$$p=(1-(1-\\frac{1}{m})^{kn})^k\\approx (1-e^{\\frac{-kn}{m}})^k $$我们先给定m,n的值，求导后得出：$$k=\\frac{m}{n}ln2$$再将求出的k值带入p的表达式中，得：$$p=(1-e^{\\frac{m}{n}ln2\\frac{n}{m}})^{\\frac{m}{n}ln2}$$进一步有：$$lnp=-\\frac{m}{n}(ln2)^2$$从而得到：$$m=-\\frac{nlnp}{(ln2)^2}$$ 参考文献布隆过滤器详解布隆过滤器的原理、使用场景和注意事那些惊艳的算法们（一）——布隆过滤器bloom filter与Cuckoo Filter布谷鸟过滤器","categories":[],"tags":[]},{"title":"人生bug之地","slug":"人生bug之地","date":"2019-10-29T00:23:09.000Z","updated":"2019-10-29T06:48:23.588Z","comments":true,"path":"2019/10/29/人生bug之地/","link":"","permalink":"http://aemonswift.github.io/2019/10/29/%E4%BA%BA%E7%94%9Fbug%E4%B9%8B%E5%9C%B0/","excerpt":"","text":"bug引入时间2019年10月27日，毕业半年多，第一次写了人生第一个bug。由于修改了别人的代码：其它服务调用此接口时会发生记录信息丢失问题，以致于线上出现了部分属性信息丢失原因。 1234567891011121314151617181920212223242526272829func (d *Dao) UpdateChannelInfo(ctx context.Context, req *v1.UpdateChannelInfoReq) (int64, error) &#123; var ( _updateChannelInfo = \"update channel set \" field []string args []interface&#123;&#125; ) if req.Name != \"\" &#123; field = append(field, \"name=? \") args = append(args, req.Name) &#125; field = append(field, \" Background=?\") //引入bug，去掉了Background不为\"\"的判断 args = append(args, req.Background) if req.Latest != 0 &#123; field = append(field, \" latest=? \") args = append(args, req.Latest) &#125; field = append(field, \" alpha=?\") args = append(args, req.Alpha) if len(args) == 0 &#123; return 0, nil &#125; args = append(args, req.Cid) res, err := d.db.Exec(ctx, _updateChannelInfo+strings.Join(field, \",\")+\" where cid=? ;\", args...) if err != nil &#123; log.Error(\"d.db.Exec() error(%v)\", err) return 0, err &#125; return res.LastInsertId()&#125; bug的原因此接口调用未考虑到有一方调用——只修改Latest属性是另外一个服务来调用；其它属性的修改又是一个服务来调用。由于自己的疏忽，未考虑到此接口供多方服务来进行调用——只修改Latest属性的调用把Background和alpha都置为0. 潜在的bug若对入参数进行这样设置： 123456789message UpdateChannelInfoReq &#123; int64 cid = 1 [(gogoproto.moretags) = \"form:\\\"cid\\\" validate:\\\"required,min=1\\\"\"]; string name = 2 [(gogoproto.moretags) = \"form:\\\"name\\\"\"]; string icon = 3 [(gogoproto.moretags) = \"form:\\\"icon\\\"\"]; string color = 4 [(gogoproto.moretags) = \"form:\\\"color\\\"\"]; string background = 5 [(gogoproto.moretags) = \"form:\\\"background\\\"\"]; int64 latest = 6 [(gogoproto.jsontag) = \"latest\", (gogoproto.casttype) = \"go-common/library/time.Time\"]; int32 alpha=7 [(gogoproto.moretags) = \"form:\\\"alpha\\\" validate=\\\"gt=0\\\"\"];&#125; 出现如下问题：有一方服务想修改Latest属性，会一直发生请求错误。因为：alpha参数属性是必须大于0的。特别是job服务很难进行排查。 如何避免类似问题 设计写接口的时候，尽量做到功能单一，且做到一个写接口只给一个服务方来调用。例如：上面只修改属性可以拆成一个接口；其它属性修改拆成另外一个接口。 测试要认真：一定要从线上，预发，以及线上灰度上面认真测试，特别是修改别人代码的接口（修改一行也要测），以及关注mysql的qps（防止接口中写入慢查询），日志的错误信息（防止请求错误过多，例如上述的参数校验导致了更新Latest属性的接口一直请求错误）。 数据库里面的数据一定要进行每日备份，错误怎么避免都会犯错的，但最坏打算就是恢复数据。 测试修改别人代码的接口时候，一定要先把之前记录copy出来，然后进行修改，进行对比，特别是线上更需要进行对比（经过大约三四个小时，再去对比几次）。通过app查看和表来查看。","categories":[{"name":"缺陷","slug":"缺陷","permalink":"http://aemonswift.github.io/categories/%E7%BC%BA%E9%99%B7/"},{"name":"工作错误","slug":"缺陷/工作错误","permalink":"http://aemonswift.github.io/categories/%E7%BC%BA%E9%99%B7/%E5%B7%A5%E4%BD%9C%E9%94%99%E8%AF%AF/"}],"tags":[{"name":"缺陷","slug":"缺陷","permalink":"http://aemonswift.github.io/tags/%E7%BC%BA%E9%99%B7/"}]},{"title":"常见限流算法","slug":"常见限流算法","date":"2019-10-28T05:19:27.000Z","updated":"2019-10-28T11:37:41.703Z","comments":true,"path":"2019/10/28/常见限流算法/","link":"","permalink":"http://aemonswift.github.io/2019/10/28/%E5%B8%B8%E8%A7%81%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/","excerpt":"","text":"为什么需要限流算法在高并发系统中，保护系统三大利器：缓存，降级，限流，即主要降低数据库的访问。当请求量超过系统负载的时候，为了保证系统正常运行，当请求达到一定的并发数或速率，就需要进行等待、排队、降级、拒绝服务等，从而保证了有效系统正常运行。按照服务调用方分为如下几种类型 与用户打交道服务 这类服务导致系统负载过高原因： 用户增长过快（好事） 某个热点事件（微博热搜） 竞争对象爬虫 恶意刷单 这类系统都是无法预知的，即弹性扩容根本不可能实现。 对内的RPC服务一个服务A的接口可能被B，C，D，E多个服务进行调用，在B服务发生突发流量时，直接把A服务给调用挂了，导致A服务对C，D，E也无法提供服务。解决方案如下：a.每个调用方采用线程池进行资源隔离；b.使用限流手段对每个调用方进行限流。 常见的限流算法计数器，令牌桶，漏桶，窗口等 计数器限流主要用来限制总并发数，比如数据库连接池大小、线程池大小、程序访问并发数等都是使用计数器算法。 计数器限流示例——通过限制系统的并发调用程度来限流例如go官方包里面httpServer频率限制，基本思路就是为连接数计数，通过make chan来建立一个最大连接数的channel, 每次accept就+1，close时候就-1. 当到达最大连接数时，就等待空闲连接出来之后再accept。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package netutil // import \"golang.org/x/net/netutil\" import ( \"net\" \"sync\") type limitListener struct &#123; net.Listener sem chan struct&#123;&#125; closeOnce sync.Once // ensures the done chan is only closed once done chan struct&#123;&#125; // no values sent; closed when Close is called&#125;type limitListenerConn struct &#123; net.Conn releaseOnce sync.Once release func()&#125; // LimitListener returns a Listener that accepts at most n simultaneous// connections from the provided Listener.func LimitListener(l net.Listener, n int) net.Listener &#123; return &amp;limitListener&#123; Listener: l, sem: make(chan struct&#123;&#125;, n), done: make(chan struct&#123;&#125;), &#125;&#125; // acquire acquires the limiting semaphore. Returns true if successfully// accquired, false if the listener is closed and the semaphore is not// acquired.func (l *limitListener) acquire() bool &#123; select &#123; case &lt;-l.done: return false case l.sem &lt;- struct&#123;&#125;&#123;&#125;: return true &#125;&#125;func (l *limitListener) release() &#123; &lt;-l.sem &#125; func (l *limitListener) Accept() (net.Conn, error) &#123; //如果sem满了，就会阻塞在这 acquired := l.acquire() // If the semaphore isn't acquired because the listener was closed, expect // that this call to accept won't block, but immediately return an error. c, err := l.Listener.Accept() if err != nil &#123; if acquired &#123; l.release() &#125; return nil, err &#125; return &amp;limitListenerConn&#123;Conn: c, release: l.release&#125;, nil&#125; func (l *limitListener) Close() error &#123; err := l.Listener.Close() l.closeOnce.Do(func() &#123; close(l.done) &#125;) return err&#125; func (l *limitListenerConn) Close() error &#123; err := l.Conn.Close() //close时释放占用的sem l.releaseOnce.Do(l.release) return err&#125;//单元测试package netutilimport ( \"errors\" \"fmt\" \"io\" \"io/ioutil\" \"net\" \"net/http\" \"sync\" \"sync/atomic\" \"testing\" \"time\" \"golang.org/x/net/internal/nettest\")func TestLimitListener(t *testing.T) &#123; const max = 5 attempts := (nettest.MaxOpenFiles() - max) / 2 if attempts &gt; 256 &#123; // maximum length of accept queue is 128 by default attempts = 256 &#125; l, err := net.Listen(\"tcp\", \"127.0.0.1:0\") if err != nil &#123; t.Fatal(err) &#125; defer l.Close() l = LimitListener(l, max) var open int32 go http.Serve(l, http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; if n := atomic.AddInt32(&amp;open, 1); n &gt; max &#123; t.Errorf(\"%d open connections, want &lt;= %d\", n, max) &#125; defer atomic.AddInt32(&amp;open, -1) time.Sleep(10 * time.Millisecond) fmt.Fprint(w, \"some body\") &#125;)) var wg sync.WaitGroup var failed int32 for i := 0; i &lt; attempts; i++ &#123; wg.Add(1) go func() &#123; defer wg.Done() c := http.Client&#123;Timeout: 3 * time.Second&#125; r, err := c.Get(\"http://\" + l.Addr().String()) if err != nil &#123; t.Log(err) atomic.AddInt32(&amp;failed, 1) return &#125; defer r.Body.Close() io.Copy(ioutil.Discard, r.Body) &#125;() &#125; wg.Wait() // We expect some Gets to fail as the kernel's accept queue is filled, // but most should succeed. if int(failed) &gt;= attempts/2 &#123; t.Errorf(\"%d requests failed within %d attempts\", failed, attempts) &#125;&#125; 使用count进行统计当前正在并发执行的次数，如果超过域值就简单粗暴的直接响应给用户，说明系统繁忙，请稍后再试或其它跟业务相关的信息。$\\color{red}{弊端：}$使用count简单粗暴超过域值就拒绝请求，可能只是瞬时的请求量高，也会拒绝请求。 计数器限流示例2——通过限制单位时间段内调用量来限流上述方法简单粗暴，一般我们会限制一秒钟的能够通过的请求数，比如限流qps为100，算法的实现思路就是从第一个请求进来开始计时，在接下去的1s内，每来一个请求，就把计数加1，如果累加的数字达到了100，那么后续的请求就会被全部拒绝。等到1s结束后，把计数恢复成0，重新开始计数。 12345678910111213141516171819202122232425262728293031323334type AbandonReqLimitService struct &#123; Interval time.Duration // 设置计数器的时间间隔 MaxCount int // 计数器的最大值 Lock sync.Mutex // 锁 ReqCount int // 计数器&#125;func CreateAbandonReqLimitService(interval time.Duration, maxCount int) *AbandonReqLimitService &#123; reqLimit := &amp;AbandonReqLimitService&#123; Interval: interval, MaxCount: maxCount, &#125; go func() &#123; // 开启一个go协程来定时更新计数器 ticker := time.NewTicker(interval) // go中的定时器 for &#123; &lt;-ticker.C reqLimit.Lock.Lock() reqLimit.ReqCount = 0 reqLimit.Lock.Unlock() &#125; &#125;() return reqLimit&#125;func (reqLimit *AbandonReqLimitService) GetTokenAbandonRequest() bool &#123; // 取令牌函数 reqLimit.Lock.Lock() defer reqLimit.Lock.Unlock() if reqLimit.ReqCount &lt; reqLimit.MaxCount &#123; reqLimit.ReqCount += 1 return true &#125; else &#123; return false &#125;&#125; $\\color{red}{弊端：}$如果我在单位时间1s内的前10ms，已经通过了100个请求，那后面的990ms，只能请求拒绝，我们把这种现象称为“突刺现象”. 计数器限流示例3——采用队列的形式形式类似信号量Semaphore。 123456789101112131415type SemaphoreService struct &#123; Semaphore chan struct&#123;&#125;&#125;func CreateSemaphore(maxCnt int) chan struct&#123;&#125;&#123; return make(chan struct&#123;&#125;,maxCnt)&#125;func(semaphore *SemaphoreService)Accquire()&#123; semaphore.Semaphore&lt;-struct&#123;&#125;&#123;&#125;&#125;func (semaphore *SemaphoreService) Release()&#123; &lt;-semaphore.Semaphore&#125; 如果是瞬时的高并发，可以使请求在阻塞队列中排队，而不是马上拒绝请求，从而达到一个流量削峰的目的。$\\color{red}{但无法应对短时间的突发流量。} 漏桶限流为了消除”突刺现象”，可以采用漏桶算法实现限流，漏桶算法这个名字就很形象，算法内部有一个容器，类似生活用到的漏斗，当请求进来时，相当于水倒入漏斗，然后从下端小口慢慢匀速的流出。不管上面流量多大，下面流出的速度始终保持不变。漏桶算法(Leaky Bucket)是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。不管服务调用方多么不稳定，通过漏桶算法进行限流，每10毫秒处理一次请求。因为处理的速度是固定的，请求进来的速度是未知的，可能突然进来很多请求，没来得及处理的请求就先放在桶里，既然是个桶，肯定是有容量上限，如果桶满了，那么新进来的请求就丢弃。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package ratelimiterimport ( \"sync\" \"time\")type rateLimiter struct &#123; lck *sync.Mutex rate float64 //最大速率限制 balance float64 //漏桶的余量 limit float64 //漏桶的最大容量限制 lastTime time.Time //上次检查的时间&#125;func NewRateLimiter(limitPerSecond int, balance int) *rateLimiter &#123; return &amp;rateLimiter&#123; lck: new(sync.Mutex), rate: float64(limitPerSecond), balance: float64(balance), limit: float64(balance), lastTime: time.Now(), &#125;&#125;func (r *rateLimiter) Check() bool &#123; ok := false r.lck.Lock() now := time.Now() dur := now.Sub(r.lastTime).Seconds() r.lastTime = now water := dur * r.rate //计算这段时间内漏桶流出水的流量water r.balance += water //漏桶流出water容量的水，自然漏桶的余量多出water if r.balance &gt; r.limit &#123; r.balance = r.limit &#125; if r.balance &gt;= 1 &#123; //漏桶余量足够容下当前的请求 r.balance -= 1 ok = true &#125; r.lck.Unlock() return ok&#125;//单元测试package ratelimiterimport ( \"fmt\" \"testing\" \"time\")func TestRateLimiter_Check(t *testing.T) &#123; limiter := NewRateLimiter(10, 1) start := time.Now() count := 0 for i := 0; i &lt; 1e3; i++ &#123; if limiter.Check() &#123; fmt.Println(i) count++ &#125; time.Sleep(time.Millisecond) &#125; fmt.Println(\"count:\", count) fmt.Println(time.Now().Sub(start).Seconds())&#125; 漏桶算法能够强行限制数据的传输速率，$\\color{blue}{但无法应对短时间的突发流量}$。 令牌桶限流从某种意义上讲，令牌桶算法是对漏桶算法的一种改进，桶算法能够限制请求调用的速率，而令牌桶算法能够在限制调用的平均速率的同时还允许一定程度的突发调用。令牌桶算法（Token Bucket）：是网络流量整形（Traffic Shaping）和速率限制（Rate Limiting）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。在令牌桶算法中，存在一个桶，用来存放固定数量的令牌。算法中存在一种机制，以一定的速率往桶中放令牌。每次请求调用需要先获取令牌，只有拿到令牌，才有机会继续执行，否则选择选择等待可用的令牌、或者直接拒绝。放令牌这个动作是持续不断的进行，如果桶中令牌数达到上限，就丢弃令牌，所以就存在这种情况，桶中一直有大量的可用令牌，这时进来的请求就可以直接拿到令牌执行，比如设置qps为100，那么限流器初始化完成一秒后，桶中就已经有100个令牌了，这时服务还没完全启动好，等启动完成对外提供服务时，该限流器可以抵挡瞬时的100个请求。所以，只有桶中没有令牌时，请求才会进行等待，最后相当于以一定的速率执行。一个简单的实现：利用的就是channel的阻塞操作。我们把一个指定尺寸channel，相当于一个指定容量的令牌桶，每一个空闲位置就是一个令牌。由于channel满时就无法向其中加元素，所以我们就可以以固定的速率消费channel中的消息（释放空间相当于添加令牌），取令牌就是添加一条消息，当令牌桶满时就无法正常添加消息（取令牌）了，这样就利用channel来构造了一个限流器。 1234567891011121314151617181920type NotAbandonReqLimitService struct &#123; TokenPool chan bool // 令牌桶&#125;func CreateNewRequestLimitService(interval time.Duration, maxCnt int) *NotAbandonReqLimitService &#123; reqLimit := &amp;NotAbandonReqLimitService&#123;&#125; reqLimit.TokenPool = make(chan bool, maxCnt) // 令牌桶最大容量 go func() &#123; tmpStr := strconv.Itoa(maxCnt) maxCntInt64,_ := strconv.ParseInt(tmpStr, 10, 64) ticker := time.NewTicker( time.Duration(interval.Nanoseconds()/(maxCntInt64*1000*1000))* time.Millisecond) // 匀速添加令牌，1s/最大qps 就是添加的速率 for &#123; &lt;- ticker.C &lt;- reqLimit.TokenPool &#125; &#125;() return reqLimit&#125;func (reqLimit *NotAbandonReqLimitService) GetTokenNotAbandonRequest() &#123; reqLimit.TokenPool &lt;- true // 消费令牌&#125; 例如go官方包rate，其思想为：用户配置的平均发送速率为r，则每隔1/r秒一个令牌被加入到桶中（每秒会有r个令牌放入桶中），桶中最多可以存放b个令牌。如果令牌到达时令牌桶已经满了，那么这个令牌会被丢弃； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349package rate import ( \"fmt\" \"math\" \"sync\" \"time\" \"golang.org/x/net/context\") // Limit defines the maximum frequency of some events.// Limit is represented as number of events per second.// A zero Limit allows no events.type Limit float64 // Inf is the infinite rate limit; it allows all events (even if burst is zero).const Inf = Limit(math.MaxFloat64) // Every converts a minimum time interval between events to a Limit.func Every(interval time.Duration) Limit &#123; if interval &lt;= 0 &#123; return Inf &#125; return 1 / Limit(interval.Seconds())&#125; // A Limiter controls how frequently events are allowed to happen.// It implements a \"token bucket\" of size b, initially full and refilled// at rate r tokens per second.// Informally, in any large enough time interval, the Limiter limits the// rate to r tokens per second, with a maximum burst size of b events.// As a special case, if r == Inf (the infinite rate), b is ignored.// See https://en.wikipedia.org/wiki/Token_bucket for more about token buckets.//// The zero value is a valid Limiter, but it will reject all events.// Use NewLimiter to create non-zero Limiters.//// Limiter has three main methods, Allow, Reserve, and Wait.// Most callers should use Wait.//// Each of the three methods consumes a single token.// They differ in their behavior when no token is available.// If no token is available, Allow returns false.// If no token is available, Reserve returns a reservation for a future token// and the amount of time the caller must wait before using it.// If no token is available, Wait blocks until one can be obtained// or its associated context.Context is canceled.//// The methods AllowN, ReserveN, and WaitN consume n tokens.type Limiter struct &#123; //maximum token, token num per second limit Limit //burst field, max token num burst int mu sync.Mutex //tokens num, change tokens float64 // last is the last time the limiter's tokens field was updated last time.Time // lastEvent is the latest time of a rate-limited event (past or future) lastEvent time.Time&#125; // Limit returns the maximum overall event rate.func (lim *Limiter) Limit() Limit &#123; lim.mu.Lock() defer lim.mu.Unlock() return lim.limit&#125; // Burst returns the maximum burst size. Burst is the maximum number of tokens// that can be consumed in a single call to Allow, Reserve, or Wait, so higher// Burst values allow more events to happen at once.// A zero Burst allows no events, unless limit == Inf.func (lim *Limiter) Burst() int &#123; return lim.burst&#125; // NewLimiter returns a new Limiter that allows events up to rate r and permits// bursts of at most b tokens.func NewLimiter(r Limit, b int) *Limiter &#123; return &amp;Limiter&#123; limit: r, burst: b, &#125;&#125; // Allow is shorthand for AllowN(time.Now(), 1).func (lim *Limiter) Allow() bool &#123; return lim.AllowN(time.Now(), 1)&#125; // AllowN reports whether n events may happen at time now.// Use this method if you intend to drop / skip events that exceed the rate limit.// Otherwise use Reserve or Wait.func (lim *Limiter) AllowN(now time.Time, n int) bool &#123; return lim.reserveN(now, n, 0).ok&#125; // A Reservation holds information about events that are permitted by a Limiter to happen after a delay.// A Reservation may be canceled, which may enable the Limiter to permit additional events.type Reservation struct &#123; ok bool lim *Limiter tokens int //This is the time to action timeToAct time.Time // This is the Limit at reservation time, it can change later. limit Limit&#125; // OK returns whether the limiter can provide the requested number of tokens// within the maximum wait time. If OK is false, Delay returns InfDuration, and// Cancel does nothing.func (r *Reservation) OK() bool &#123; return r.ok&#125; // Delay is shorthand for DelayFrom(time.Now()).func (r *Reservation) Delay() time.Duration &#123; return r.DelayFrom(time.Now())&#125; // InfDuration is the duration returned by Delay when a Reservation is not OK.const InfDuration = time.Duration(1&lt;&lt;63 - 1) // DelayFrom returns the duration for which the reservation holder must wait// before taking the reserved action. Zero duration means act immediately.// InfDuration means the limiter cannot grant the tokens requested in this// Reservation within the maximum wait time.func (r *Reservation) DelayFrom(now time.Time) time.Duration &#123; if !r.ok &#123; return InfDuration &#125; delay := r.timeToAct.Sub(now) if delay &lt; 0 &#123; return 0 &#125; return delay&#125; // Cancel is shorthand for CancelAt(time.Now()).func (r *Reservation) Cancel() &#123; r.CancelAt(time.Now()) return&#125; // CancelAt indicates that the reservation holder will not perform the reserved action// and reverses the effects of this Reservation on the rate limit as much as possible,// considering that other reservations may have already been made.func (r *Reservation) CancelAt(now time.Time) &#123; if !r.ok &#123; return &#125; r.lim.mu.Lock() defer r.lim.mu.Unlock() if r.lim.limit == Inf || r.tokens == 0 || r.timeToAct.Before(now) &#123; return &#125; // calculate tokens to restore // The duration between lim.lastEvent and r.timeToAct tells us how many tokens were reserved // after r was obtained. These tokens should not be restored. restoreTokens := float64(r.tokens) - r.limit.tokensFromDuration(r.lim.lastEvent.Sub(r.timeToAct)) if restoreTokens &lt;= 0 &#123; return &#125; // advance time to now now, _, tokens := r.lim.advance(now) // calculate new number of tokens tokens += restoreTokens if burst := float64(r.lim.burst); tokens &gt; burst &#123; tokens = burst &#125; // update state r.lim.last = now r.lim.tokens = tokens if r.timeToAct == r.lim.lastEvent &#123; prevEvent := r.timeToAct.Add(r.limit.durationFromTokens(float64(-r.tokens))) if !prevEvent.Before(now) &#123; r.lim.lastEvent = prevEvent &#125; &#125; return&#125; // Reserve is shorthand for ReserveN(time.Now(), 1).func (lim *Limiter) Reserve() *Reservation &#123; return lim.ReserveN(time.Now(), 1)&#125; // ReserveN returns a Reservation that indicates how long the caller must wait before n events happen.// The Limiter takes this Reservation into account when allowing future events.// ReserveN returns false if n exceeds the Limiter's burst size.// Usage example:// r, ok := lim.ReserveN(time.Now(), 1)// if !ok &#123;// // Not allowed to act! Did you remember to set lim.burst to be &gt; 0 ?// &#125;// time.Sleep(r.Delay())// Act()// Use this method if you wish to wait and slow down in accordance with the rate limit without dropping events.// If you need to respect a deadline or cancel the delay, use Wait instead.// To drop or skip events exceeding rate limit, use Allow instead.func (lim *Limiter) ReserveN(now time.Time, n int) *Reservation &#123; r := lim.reserveN(now, n, InfDuration) return &amp;r&#125; // Wait is shorthand for WaitN(ctx, 1).func (lim *Limiter) Wait(ctx context.Context) (err error) &#123; return lim.WaitN(ctx, 1)&#125; // WaitN blocks until lim permits n events to happen.// It returns an error if n exceeds the Limiter's burst size, the Context is// canceled, or the expected wait time exceeds the Context's Deadline.func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) &#123; if n &gt; lim.burst &#123; return fmt.Errorf(\"rate: Wait(n=%d) exceeds limiter's burst %d\", n, lim.burst) &#125; // Check if ctx is already cancelled select &#123; case &lt;-ctx.Done(): return ctx.Err() default: &#125; // Determine wait limit now := time.Now() waitLimit := InfDuration if deadline, ok := ctx.Deadline(); ok &#123; waitLimit = deadline.Sub(now) &#125; // Reserve r := lim.reserveN(now, n, waitLimit) if !r.ok &#123; return fmt.Errorf(\"rate: Wait(n=%d) would exceed context deadline\", n) &#125; // Wait t := time.NewTimer(r.DelayFrom(now)) defer t.Stop() select &#123; case &lt;-t.C: // We can proceed. return nil case &lt;-ctx.Done(): // Context was canceled before we could proceed. Cancel the // reservation, which may permit other events to proceed sooner. r.Cancel() return ctx.Err() &#125;&#125; // SetLimit is shorthand for SetLimitAt(time.Now(), newLimit).func (lim *Limiter) SetLimit(newLimit Limit) &#123; lim.SetLimitAt(time.Now(), newLimit)&#125; // SetLimitAt sets a new Limit for the limiter. The new Limit, and Burst, may be violated// or underutilized by those which reserved (using Reserve or Wait) but did not yet act// before SetLimitAt was called.func (lim *Limiter) SetLimitAt(now time.Time, newLimit Limit) &#123; lim.mu.Lock() defer lim.mu.Unlock() now, _, tokens := lim.advance(now) lim.last = now lim.tokens = tokens lim.limit = newLimit&#125; // reserveN is a helper method for AllowN, ReserveN, and WaitN.// maxFutureReserve specifies the maximum reservation wait duration allowed.// reserveN returns Reservation, not *Reservation, to avoid allocation in AllowN and WaitN.func (lim *Limiter) reserveN(now time.Time, n int, maxFutureReserve time.Duration) Reservation &#123; lim.mu.Lock() defer lim.mu.Unlock() if lim.limit == Inf &#123; return Reservation&#123; ok: true, lim: lim, tokens: n, timeToAct: now, &#125; &#125; now, last, tokens := lim.advance(now) // Calculate the remaining number of tokens resulting from the request. tokens -= float64(n) // Calculate the wait duration var waitDuration time.Duration if tokens &lt; 0 &#123; waitDuration = lim.limit.durationFromTokens(-tokens) &#125; // Decide result ok := n &lt;= lim.burst &amp;&amp; waitDuration &lt;= maxFutureReserve // Prepare reservation r := Reservation&#123; ok: ok, lim: lim, limit: lim.limit, &#125; if ok &#123; r.tokens = n r.timeToAct = now.Add(waitDuration) &#125; // Update state if ok &#123; lim.last = now lim.tokens = tokens lim.lastEvent = r.timeToAct &#125; else &#123; lim.last = last &#125; return r&#125; // advance calculates and returns an updated state for lim resulting from the passage of time.// lim is not changed.func (lim *Limiter) advance(now time.Time) (newNow time.Time, newLast time.Time, newTokens float64) &#123; last := lim.last if now.Before(last) &#123; last = now &#125; // Avoid making delta overflow below when last is very old. maxElapsed := lim.limit.durationFromTokens(float64(lim.burst) - lim.tokens) elapsed := now.Sub(last) if elapsed &gt; maxElapsed &#123; elapsed = maxElapsed &#125; // Calculate the new number of tokens, due to time that passed. delta := lim.limit.tokensFromDuration(elapsed) tokens := lim.tokens + delta if burst := float64(lim.burst); tokens &gt; burst &#123; tokens = burst &#125; return now, last, tokens&#125; // durationFromTokens is a unit conversion function from the number of tokens to the duration// of time it takes to accumulate them at a rate of limit tokens per second.func (limit Limit) durationFromTokens(tokens float64) time.Duration &#123; seconds := tokens / float64(limit) return time.Nanosecond * time.Duration(1e9*seconds)&#125; // tokensFromDuration is a unit conversion function from a time duration to the number of tokens// which could be accumulated during that duration at a rate of limit tokens per second.func (limit Limit) tokensFromDuration(d time.Duration) float64 &#123; return d.Seconds() * float64(limit)&#125; 虽然在某些情况下使用单个全局速率限制器非常有用，但另一种常见情况是基于IP地址或API密钥等标识符为每个用户实施速率限制器。我们将使用IP地址作为标识符。简单实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package mainimport ( \"net/http\" \"sync\" \"time\" \"golang.org/x/time/rate\")// Create a custom visitor struct which holds the rate limiter for each// visitor and the last time that the visitor was seen.type visitor struct &#123; limiter *rate.Limiter lastSeen time.Time&#125;// Change the the map to hold values of the type visitor.var visitors = make(map[string]*visitor)var mtx sync.Mutex// Run a background goroutine to remove old entries from the visitors map.func init() &#123; go cleanupVisitors()&#125;func addVisitor(ip string) *rate.Limiter &#123; limiter := rate.NewLimiter(2, 5) mtx.Lock() // Include the current time when creating a new visitor. visitors[ip] = &amp;visitor&#123;limiter, time.Now()&#125; mtx.Unlock() return limiter&#125;func getVisitor(ip string) *rate.Limiter &#123; mtx.Lock() v, exists := visitors[ip] if !exists &#123; mtx.Unlock() return addVisitor(ip) &#125; // Update the last seen time for the visitor. v.lastSeen = time.Now() mtx.Unlock() return v.limiter&#125;// Every minute check the map for visitors that haven't been seen for// more than 3 minutes and delete the entries.func cleanupVisitors() &#123; for &#123; time.Sleep(time.Minute) mtx.Lock() for ip, v := range visitors &#123; if time.Now().Sub(v.lastSeen) &gt; 3*time.Minute &#123; delete(visitors, ip) &#125; &#125; mtx.Unlock() &#125;&#125;func limit(next http.Handler) http.Handler &#123; return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; limiter := getVisitor(r.RemoteAddr) if limiter.Allow() == false &#123; http.Error(w, http.StatusText(429), http.StatusTooManyRequests) return &#125; next.ServeHTTP(w, r) &#125;)&#125; 窗口限流Fixed Window固定窗口算法，设置一个时间段内（窗口）接收的请求数，超过的这个请求数的请求会被丢弃。 窗口通常选择人们熟悉的时间段：1 分钟／1小时 窗口的起始时间通常是当前时间取地板（floor），比如 12:00:03 所在的窗口 （以一分钟的窗口为例）就是 12:00:00 - 12:01:00和漏桶相比，能够让新来的请求也能够被处理到，但存在缺点： 在窗口的起始时间，最差情况下可能会带来 2 倍的流量 很多消费者可能都在等待窗口被重置，造成惊群效应（惊群效应：当某一资源可用时，n个进程/线程会惊醒，竞争资源。导致n-1个进程/线程做了无效的调度,上下文切换，cpu瞬时增高） Sliding Log滑动日志算法，利用记录下来的用户的请求时间，请求数，当该用户的一个新的 请求进来时，比较这个用户在这个窗口内的请求数是否超过了限定值，超过的话 就拒绝这个请求。优点： 避免了固定窗口算法在窗口边界可能出现的两倍流量问题 由于是针对每个用户进行统计的，不会引发惊群效应缺点： 需要保存大量的请求日志 每个请求都需要考虑该用户之前的请求情况，在分布式系统中尤其难做到 Sliding Window滑动窗口算法，结合了固定窗口算法的低开销和滑动日志算法能够解决的边界情况。 为每个窗口进行请求量的计数 结合上一个窗口的请求量和这一个窗口已经经过的时间来计算出上限，以此 平滑请求尖锋举例来说，限流的上限是每分钟 10 个请求，窗口大小为 1 分钟，上一个 窗口中总共处理了 6 个请求。现在假设这个新的窗口已经经过了 20 秒，那么 到目前为止允许的请求上限就是 10 - 6 * (1 - 20 / 60) = 8。滑动窗口算法是这些算法中最实用的算法： 避免了漏桶算法带来的饥饿问题 避免了固定窗口算法的请求量突增的问题 集群限流上述限流方法都是单机限流的范畴，比如为了限制某个资源被每个用户或者商户的访问次数，5s只能访问2次，或者一天只能调用1000次，这种需求，单机限流是无法实现的，这时就需要通过集群限流进行实现。难点在于限流上限都是针对全站的流量设置的，那么每个节点该如何协调各自处理的量呢？ 同步的策略解决的方法通常都是使用一个统一的数据库来存放计数，比如 Redis 或者 Cassandra。 数据库中将存放每个窗口和用户的计数值。这种方法的主要问题是需要多访问一次数据库， 以及竞争问题。 竞争问题竞争问题就是当有两个以上的线程同时执行 i += 1 的时候，如果没有同步这 些操作的话，i 的值可能会有多种情况。处理竞争问题可以通过加锁来做，不过在限流的场景下，这样做肯定会成为系统的瓶颈， 毕竟限流时每个请求都会来竞争这个锁。更好的办法是通过 set-then-get 的方法，限流场景中用到的只是计数 +1， 利用这一点以及数据库实现的性能更好的原子操作可以达到我们的目的。 性能优化利用集中式的数据库的另一个问题是每次请求都要查一下数据库带来的延迟开销， 数据库再快也会带来几毫秒的延迟。解决这个问题的方法可以通过在内存里面维护一个计数值，代价是稍微的放松限 流的精确度。通过设置一个定时任务从数据库拿计数值，周期内在内存中维护这 个计数，周期结束时把计数同步到数据库并拿取新的计数，如此往复。这个同步周期往往是做成可以配置的，小的周期能够带来更精确的限流， 大的周期则能减轻数据库的 I/O 压力。 参考文献基于令牌桶算法和漏桶算法来实现的限速限流轻量级限流中间件漏桶算法&amp;令牌桶算法理解及常用的算法go channel实现简单信号量go语言生产者消费者信号量实现Golang实现请求限流的几种办法高并发系统限流-漏桶算法和令牌桶算法谈谈服务限流算法的几种实现常用的限流算法高并发系统限流中的漏桶算法和令牌桶算法，通过流量整形和速率限制提升稳定性高并发系统限流中的算法限流算法比较与实现接口限流算法（关于临界点处理）限流算法的理解和应用场景和实现高并发中的惊群效应","categories":[{"name":"系统","slug":"系统","permalink":"http://aemonswift.github.io/categories/%E7%B3%BB%E7%BB%9F/"},{"name":"限流","slug":"系统/限流","permalink":"http://aemonswift.github.io/categories/%E7%B3%BB%E7%BB%9F/%E9%99%90%E6%B5%81/"}],"tags":[{"name":"系统","slug":"系统","permalink":"http://aemonswift.github.io/tags/%E7%B3%BB%E7%BB%9F/"},{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"路径规划——Floyd","slug":"路径规划——Floyd","date":"2019-10-25T01:22:00.000Z","updated":"2019-10-25T02:28:56.736Z","comments":true,"path":"2019/10/25/路径规划——Floyd/","link":"","permalink":"http://aemonswift.github.io/2019/10/25/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92%E2%80%94%E2%80%94Floyd/","excerpt":"","text":"思想$\\color{red}{主要用来求解：}$任意两点的最短路径。该算法采用了动态规划的思想。$\\color{red}{思想如下：}$A到B，可以经历中转站得来降低成本；当考虑了所有的中转站的时候，则可以得到此图在A到B的最低成本。\b$\\color{red}{适用范围：}$解决多源路径问题。 算法步骤 初始化边矩阵M； 从U中选取顶点k加入S中，并将此元素从U中移除； 以k为中转站，更新边矩阵M的信息； 重复步骤2和3，直到所有顶点都包含在S中。例子 a. 初始化M矩阵,即经过A点的M矩阵 * A B C D E F A 0 6 3 $\\infty$ $\\infty$ $\\infty$ B 6 0 2 5 $\\infty$ $\\infty$ C 3 2 0 3 4 $\\infty$ D $\\infty$ 5 3 0 2 3 E $\\infty$ $\\infty$ 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 b. 考虑经过B点，更新M矩阵 * A B C D E F A 0 6 3 11 $\\infty$ $\\infty$ B 6 0 2 5 $\\infty$ $\\infty$ C 3 2 0 3 4 $\\infty$ D 11 5 3 0 2 3 E $\\infty$ $\\infty$ 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 c. 考虑经过C点，更新M矩阵 * A B C D E F A 0 5 3 6 7 $\\infty$ B 5 0 2 5 6 $\\infty$ C 3 2 0 3 4 $\\infty$ D 6 5 3 0 2 3 E 7 6 4 2 0 5 F $\\infty$ $\\infty$ $\\infty$ 3 5 0 d. 考虑经过D点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 e. 考虑经过E点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 f. 考虑经过F点，更新M矩阵 * A B C D E F A 0 5 3 6 7 9 B 5 0 2 5 6 8 C 3 2 0 3 4 6 D 6 5 3 0 2 3 E 7 6 4 2 0 5 F 9 8 6 3 5 0 算法实现头文件描述123456789101112131415161718192021222324pragma once#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;stringstream&gt;using namespace std;class GraphDG&#123;private: int pointSum; int edge; int **adjacentMat； int **dis; int **path; string intToString(int target) bool checkEdgeValue(int start,int end,int weight);public: GraphDG(int pointSum,int edge); ~GraphDG(); void createGraph(int); void print(); void Floyd(); void printMinPath();&#125;; 功能实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113# include \"Floyd.h\"const INT_MAX=2^32-1;GraphDG::GraphDG(int pointSum,int edge)&#123; this-&gt;pointSum=pointSum; this-&gt;edge=edge; this-&gt;adjacentMat=new int*[this-&gt;pointSum]; this-&gt;dis=new int*[this-&gt;pointSum]; this-&gt;path=new int*[this-&gt;pointSum]; for(int i=0;i&lt;this-&gt;pointSum;i++)&#123; adjacentMat[i]=new int[this-&gt;pointSum]; dis[i]=new int[this-&gt;pointSum]; path[i]=new int[this-&gt;pointSum]; for (int j=0;j&lt;this-&gt;pointSum;j++)&#123; adjacentMat[i][j]=INT_MAX; &#125; &#125;&#125;GraphDG::~GraphDG()&#123; for (int i=0;i&lt;this-&gt;pointSum;i++)&#123; delete adjacentMat[i]; delete dis[i]; delete path[i]; &#125; delete adjacentMat; delete dis; delete path;&#125;bool GraphDG::checkEdgeValue(int start,int end,int weight)&#123; if (start&lt;1||end&lt;1||start&gt;end||end&gt;pointSum||weight&lt;0)&#123; return false; &#125; return true;&#125;void GraphDG::createGraph(int kind)&#123; cout &lt;&lt; \"请输入每条边的起点和终点（顶点编号从1开始）以及其权重\" &lt;&lt; endl; int start,end,weight; for (int i=0;i&lt;this-&gt;edge;i++&gt;)&#123; cin&gt;&gt;start&gt;&gt;end&gt;&gt;weight; while(!this-&gt;checkEdgeValue(start,end,weight))&#123; cout &lt;&lt; \"输入的边的信息不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; start &gt;&gt; end &gt;&gt; weight; &#125; adjacentMat[start-1][end-1]=weight; //变成无向图 if (kind==2)&#123; adjacentMat[end-1][start-1]=weight; &#125; &#125;&#125;void GraphDG::print()&#123; cout &lt;&lt; \"图的邻接矩阵为：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointSum;row++&gt;)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; if adjacentMat[row][col]==INT_MAX&#123; cout&lt;&lt;\"i \"; &#125;else&#123; cout&lt;&lt;adjacentMat[row][col]&lt;&lt;\" \"; &#125; &#125; cout&lt;&lt;endl; &#125; cout &lt;&lt;endl;&#125;//思想在于：A到B，可以经历中转站得来降低成本；当考虑了所有的中转站的时候，则可以得到此图在A到B的最低成本。——动态规划思想void GraphDG::Floyd()&#123; for (int row=0;row&lt;this-&gt;pointSum;row++)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; this-&gt;dis[row][col]=this-&gt;adjacentMat[row][col]; this-&gt;path[row][col]=col; &#125; &#125; for (int temp =0;temp&lt;this-&gt;pointSum;temp++)&#123; //temp为中转站 for (int i=0;i&lt;this-&gt;pointSum;i++)&#123; for(int j=0;j&lt;this-&gt;pointSum;j++)&#123; select=(dis[row][temp] == INT_MAX || dis[temp][col] == INT_MAX) ? INT_MAX : (dis[row][temp] + dis[temp][col]); if(this-&gt;dis[i][j]&gt;select)&#123; this-&gt;dis[i][j]=select; this-&gt;path[i][j]=this-&gt;path[i][temp]; &#125; &#125; &#125; &#125;&#125;void GraphDG::printMinPath()&#123; cout &lt;&lt; \"各个顶点对的最短路径：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointSum;row++)&#123; for (int col=0;col&lt;this-&gt;pointSum;col++)&#123; cout&lt;&lt;\"v\"&lt;&lt;intToString(row+1)&lt;&lt;\"--\"&lt;&lt;\"v\"&lt;&lt;intToString(col+1)&lt;&lt;\"weight:\" &lt;&lt;this-&gt;dis[row][col]&lt;&lt;\"path:\"&lt;&lt;\"v\"&lt;&lt;intToString(row+1); temp=path[row][col]; while(temp!=col)&#123; cout&lt;&lt;\"--&gt;\"&lt;&lt;\"v\"&lt;&lt;intToString(temp+1); temp=path[temp][col]; &#125; cout&lt;&lt;\"--&gt;\"&lt;&lt;\"v\"&lt;&lt;intToString(col+1)&lt;&lt;endl; &#125; cout&lt;&lt;endl; &#125;&#125;string GraphDG::intToString(int target)&#123; stringstream ss; ss&lt;&lt;target; return ss&gt;&gt;; &#125; 测试函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include \"Floyd.h\"bool check(int pointSum,int edge)&#123; if (pointSum&lt;=1||edge&lt;=0||(pointSum-1)*pointSum&lt;edge)&#123; return false; &#125; return true;&#125;int main()&#123; int pointSum,edge,kind; cout &lt;&lt; \"输入图的种类：1代表有向图，2代表无向图\" &lt;&lt; endl; cin&gt;&gt;kind; while(true)&#123; if (kind==1||kind==2)&#123; break; &#125;else&#123; cout &lt;&lt; \"输入的图的种类编号不合法，请重新输入：1代表有向图，2代表无向图\" &lt;&lt; endl; cin &gt;&gt; kind; &#125; &#125; cout &lt;&lt; \"输入图的顶点个数和边的条数：\" &lt;&lt; endl; cin &gt;&gt; pointSum &gt;&gt; edge; while (!check(pointSum, edge)) &#123; cout &lt;&lt; \"输入的数值不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; pointSum &gt;&gt; edge; &#125; GraphDG graph(pointSum,edge); graph.createGraph(kind); graph.print(); graph.Floy(); graph.printMinPath(); system(\"pause\"); return 0&#125;//输入参数// 2// 7 12// 1 2 12// 1 6 16// 1 7 14// 2 3 10// 2 6 7// 3 4 3// 3 5 5// 3 6 6// 4 5 4// 5 6 2// 5 7 8// 6 7 9 算法缺陷可以求有负权值的边，但是不能有负回路。","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"算法/路径规划","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"路径规划","permalink":"http://aemonswift.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]},{"title":"路径规划——Dijkstra","slug":"路径规划——Dijkstra","date":"2019-10-24T07:03:06.000Z","updated":"2019-10-25T01:45:09.631Z","comments":true,"path":"2019/10/24/路径规划——Dijkstra/","link":"","permalink":"http://aemonswift.github.io/2019/10/24/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92%E2%80%94%E2%80%94Dijkstra/","excerpt":"","text":"思想$\\color{red}{主要用来求解：}$从起始点到其他所有点的最短路径。该算法采用了贪心的思想。$\\color{red}{思想如下：}$A到B可以有多个中转站集合U，如何选择中转站？本算法选择最低的成本的中转站，即将C1加入到需要走的中转站集合S中，在目前集合S情况下，得到了A到所有各站的成本，在此成本基础上选择最低的成本加入到需要走的中转站集合S中，重复上述操作。\b$\\color{red}{适用范围：}$解决单源路径问题。 算法步骤 初始化时，S只含有源节点； 从U中选取一个距离v最小的顶点k加入S中（该选定的距离就是v到k的最短路径长度），并将此元素从U中移除； 以k为新考虑的中间点，修改U中各顶点的距离；若从源节点v到顶点u的距离（经过顶点k）比原来距离（不经过顶点k）短，则修改顶点u的距离值，修改后的距离值是顶点k的距离加上k到u的距离； 重复步骤2和3，直到所有顶点都包含在S中。例子从A开始出发，到其他所有点的最短距离和路径 步骤 描述 1 初始化距离$dis=[0,6,3,\\infty,\\infty,\\infty,\\infty]$，此时S={A},U={B,C,D,E,F} 2 排除S中的点，寻找dis中最小距离的点C,此时距离为$dis=[0,5,3,6,7,\\infty]$，此时S={A,C},U={B,D,E,F} 3 排除S中的点，寻找dis中最小距离的点B，此时距离变为$dis=[0,5,3,6,7,\\infty]$，此时S={A,C,B},U={D,E,F} 4 排除S中的点，寻找dis中最小距离的点D，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D},U={E,F} 5 排除S中的点，寻找dis中最小距离的点E，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D,E},U={F} 6 排除S中的点，寻找dis中最小距离的点F，此时距离变为$dis=[0,5,3,6,7,9]$，此时S={A,C,B,D,F},U={} 算法实现头文件描述1234567891011121314151617181920212223242526272829303132333435363738// Dijkstra.h# pragma once //pragma once是一个比较常用的C/C++声明，只要在头文件的最开始加入这条杂注，就能够保证头文件只被编译一次。# include &lt;iostream&gt;# include &lt;string&gt;#include &lt;sstream&gt;using namespace std;struct Dis&#123; string path; int value; bool visit; int prePoint; //记录到当前节点的上一个节点是谁 Dis()&#123; visit=false; value=0; path=\"\"; minPath=nullptr; &#125;&#125;;class GraphDG&#123;private: int pointNum; int edge; int **adjacentMat； Dis*dis; string intToString(int target); bool checkEdgeValue(int start,int end,int weight);public: GraphDG(int pointNum,int edge); ~GraphDG(); void createGraph(); void print(); void resloveMinPath(int begin); void printSearchPath(int begin); void printMinPath(int begin,int end);&#125;; 功能实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125# include \"Dijkstra.h\"const INT_MAX=2^31-1;GraphDG::GraphDG(int pointNum,int edge)&#123; this-&gt;pointNum=pointNum; this-&gt;edge=edge; adjacentMat=new int* [this-&gt;pointNum]; dis=new Dis[this-&gt;pointNum]; for(int i=0;i&lt;this-&gt;pointNum;i++)&#123; adjacentMat=new int[this-&gt;pointNum]; for int(j=0;j&lt;this-&gt;pointNum;j++)&#123; adjacentMat[i][j]=INT_MAX; //开始赋值无穷大 &#125; &#125;&#125;GraphDG::~GraphDG() &#123; delete dis; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; delete this-&gt;adjacentMat[i]; &#125; delete this-&gt;adjacentMat;&#125;bool GraphDG::checkEdgeValue(int start,int end,int weight)&#123; if (start&lt;1||end&lt;1||start&gt;this-&gt;pointNum||end&gt;this-&gt;pointNum||weight&lt;0)&#123; return false; &#125; return true;&#125;void GraphDG::createGraph()&#123; cout &lt;&lt; \"请输入每条边的起点和终点（顶点编号从1开始）以及其权重\" &lt;&lt; endl; int start,end,weight,count=0; while(count!=this-&gt;edge)&#123; cin&gt;&gt;start&gt;&gt;end&gt;&gt;weight; while(!this-&gt;checkEdgeValue(start,end,weight))&#123; cout &lt;&lt; \"输入的边的信息不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; start &gt;&gt; end &gt;&gt; weight; &#125; adjacentMat[start-1][end-1]=weight; // adjacentMat[end-1][start-1]=weight 加上这句为无向边 count++; &#125;&#125;void GraphDG::print(int begin)&#123; cout &lt;&lt; \"图的邻接矩阵为：\" &lt;&lt; endl; for (int row=0;row&lt;this-&gt;pointNum;col++)&#123; for(int col=0;col&lt;this-&gt;pointNum;i++;col++)&#123; if (adjacentMat[row][col]==INT_MAX)&#123; cout&lt;&lt;\"infinity\"； &#125;else&#123; cout&lt;&lt;adjacentMat[row][col]; &#125; &#125; cout&lt;&lt;endl; &#125; cout&lt;&lt;endl;&#125;void GraphDG::printSearchPath(int begin)&#123; string str; str=\"v\"+intToString(begin); cout &lt;&lt; \"以\"&lt;&lt;str&lt;&lt;\"为起点的图的最短路径为：\" &lt;&lt; endl; for (int i=0;i!=this-&gt;pointNum;i++)&#123; if(dis[i].value!=INT_MAX)&#123; cout &lt;&lt; dis[i].path &lt;&lt; \"=\" &lt;&lt; dis[i].value &lt;&lt; endl; &#125;else&#123; cout &lt;&lt; dis[i].path &lt;&lt; \"是无最短路径的\" &lt;&lt; endl; &#125; &#125;&#125;void GraphDG::printMinpath(int begin,int end)&#123; string str; int prePoint=dis[end].prePoint; while(prePoint&gt;=0)&#123; proPoint=dis[prePoint].prePoint; if (prePoint==proPoint)&#123; break; &#125; str=intToString(prePoint+1)+\" \"+str; prePoint=proPoint; &#125; cout&lt;&lt;str;&#125;void GraphDG::Dijkstra(int begin)&#123; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; dis[i].path=\"v\"+intToString(begin)+\"--&gt;v\"+intToString(i+1); dis[i].value=adjacentMat[begin-1][i]; dis[i].prePoint=begin; &#125; dis[begin-1].value=0; dis[begin-1].visit=true; for (int count=1;count&lt;this-&gt;pointNum;count++)&#123; //找加入的最小值对应的下标 int temp=0,min=INT_MAX; for (int i=0;i&lt;this-&gt;pointNum;i++)&#123; if(!dis[i].visit&amp;&amp;dis[i].value&lt;INT_MAX)&#123; min=dis[i].value; temp=i &#125; &#125; dis[temp].visit=true; // 计算剩余点的最短路径 for (int i=0;i&lt;this-&gt;pointNum;i++&gt;)&#123; //注意这里的条件adjacentMat[temp][i]!=INT_MAX必须加，不然会出现溢出，从而造成程序异常 if(!dis[i].visit&amp;&amp;adjacentMat[temp][i]!=INT_MAX&amp;&amp;dis[temp].value+adjacentMat[temp][i]&lt;dis[i].value)&#123; dis[i].value=dis[temp].value+adjacentMat[temp][i]; dis[i].path=dis[temp].path+\"--&gt;v\"+intToString(i+1); dis[i].prePoint=temp; &#125; &#125; &#125;&#125;string GraphDG::intToString(int target)&#123; stringstream ss; ss&lt;&lt;target; return ss&gt;&gt;; &#125; 测试函数123456789101112131415161718192021222324252627282930313233343536#include \"Dijkstra.h\"bool check(int pointNum,int edge)&#123; if(pointNum&lt;=1||edge&lt;=0||(pointNum-1)*pointNum/2&lt;edge)&#123; return false; &#125; return true;&#125;int main()&#123; int pointNum,edge; cout &lt;&lt; \"输入图的顶点个数和边的条数：\" &lt;&lt; endl; cin &gt;&gt; pointNum &gt;&gt; edge; while (!check(vexnum, edge)) &#123; cout &lt;&lt; \"输入的数值不合法，请重新输入\" &lt;&lt; endl; cin &gt;&gt; pointNum &gt;&gt; edge; &#125; GraphDG grpah(pointNum,edge); graph.createGraph(); graph.print(); graph.Dijkstra(); graph.printSearchPath(); graph.printMinPath(); system(\"pause\"); return 0;&#125;//输入参数// 6 8// 1 3 10// 1 5 30// 1 6 100// 2 3 5// 3 4 50// 4 6 10// 5 6 60// 5 4 20 算法缺陷若权重为负边的时候，此算法失效。","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"算法/路径规划","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"路径规划","slug":"路径规划","permalink":"http://aemonswift.github.io/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/"}]},{"title":"冒泡算法及其优化","slug":"冒泡算法及其优化","date":"2019-10-23T07:01:32.000Z","updated":"2019-10-24T02:03:06.983Z","comments":true,"path":"2019/10/23/冒泡算法及其优化/","link":"","permalink":"http://aemonswift.github.io/2019/10/23/%E5%86%92%E6%B3%A1%E7%AE%97%E6%B3%95%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96/","excerpt":"","text":"思想给你一个数列，对相邻的两个个数进行比较，让大数下沉，或较小的数字进行上浮。 算法实现一般实现方法123456789101112void BubbleSort(int arr[],int len)&#123; int tmp=0; for (int i=0;i&lt;len;i++)&#123; for(int j=0;j&lt;len-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; &#125; &#125; &#125;&#125; 上述算法实现的缺陷：若排到一定时候，当数列再也没有发生交换（即顺序已经排好），但仍然进行循环。 优化1——\b引入有序标记针对一般实现方法，引入一个标记 flag，来判断是否发生来交换 1234567891011121314151617void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0; for (int i=0;i&lt;len;i++)&#123; flag=0; for(int j=0;j&lt;len-i-1;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; &#125; &#125; if (flag==0)&#123; return; &#125; &#125;&#125; 上述算法实现仍然有着缺陷：若排到一定时候，后面部分都有顺序，而只是前面部分没有顺序，会进行不必要的循环次数。 优化2——引入位置标记针对优化1实现的方法，引入一个位置标记pos，来记录从哪个位置开始时，后面的数据都有顺序。 1234567891011121314151617181920void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0,pos=0,k=len-1; for (int i=0;i&lt;len;i++)&#123; flag=0; pos=0; for(int j=0;j&lt;k;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; pos=j; &#125; &#125; if (flag==0)&#123; return; &#125; k=pos; &#125;&#125; 还没有方法来继续提高效率？ 优化3——鸡尾酒排序回归到冒泡思想：给你一个数列，对相邻的两个个数进行比较，让大数下沉，或较小的数字进行上浮。若一次排序让大数和小数一并都找到，这样大大缩小了第一层的循环次数。——称为鸡尾酒排序。pos标记从哪个位置开始时，后面的数据都有顺序。prepos标记从哪个位置开始时，前面的数据都有顺序。 12345678910111213141516171819202122232425262728293031323334void BubbleSort(int arr[],int len)&#123; int tmp=0,flag=0,pos=0,k=len-1,prepos=0; for (int i=0;i&lt;len;i++)&#123; flag=0; pos=0; for(int j=i;j&lt;k;j++)&#123; if (arr[j]&gt;arr[j+1])&#123; tmp=arr[j]; arr[j]=arr[j+1]; arr[j+1]=tmp; flag=1; pos=j; &#125; &#125; if (flag==0)&#123; return; &#125; k=pos; flag=0; for (int j=k;j&gt;i;j--)&#123; if (arr[j]&lt;arr[j-1])&#123; tmp=arr[j]; arr[j]=arr[j-1]; arr[j-1]=tmp; flag=1; prepos=j; &#125; &#125; if (flag==0)&#123; return; &#125; i=prepos-1; //由于i++操作，故需要进行减1操作，才能回到从哪个位置开始，前面都有序 &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/"},{"name":"排序","slug":"算法/排序","permalink":"http://aemonswift.github.io/categories/%E7%AE%97%E6%B3%95/%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://aemonswift.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"hello","slug":"hello","date":"2019-10-21T12:01:35.000Z","updated":"2019-10-22T00:59:53.081Z","comments":true,"path":"2019/10/21/hello/","link":"","permalink":"http://aemonswift.github.io/2019/10/21/hello/","excerpt":"","text":"问题描述问题为什么重要问题目前解决方案有哪些问题的难点是什么你的创新点是什么问题求解问题数学描述问世间，何许人也！","categories":[{"name":"音乐","slug":"音乐","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/"},{"name":"前端","slug":"音乐/前端","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/%E5%89%8D%E7%AB%AF/"},{"name":"后端","slug":"音乐/前端/后端","permalink":"http://aemonswift.github.io/categories/%E9%9F%B3%E4%B9%90/%E5%89%8D%E7%AB%AF/%E5%90%8E%E7%AB%AF/"}],"tags":[{"name":"古典","slug":"古典","permalink":"http://aemonswift.github.io/tags/%E5%8F%A4%E5%85%B8/"},{"name":"轻音乐","slug":"轻音乐","permalink":"http://aemonswift.github.io/tags/%E8%BD%BB%E9%9F%B3%E4%B9%90/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-10-21T00:53:07.676Z","updated":"2019-10-21T00:53:07.676Z","comments":true,"path":"2019/10/21/hello-world/","link":"","permalink":"http://aemonswift.github.io/2019/10/21/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}